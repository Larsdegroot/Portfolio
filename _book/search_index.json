[["portfolio-assignment-1-1.html", "Portfolio of DSFB 1 Portfolio assignment 1.1", " Portfolio of DSFB Lars de Groot 1 Portfolio assignment 1.1 A. Review the following Excel file in the ./data/CE.LIQ.FLOW.062_Tidydata.xlsx (its here), by opening the file in Excel. See if you can spot anything peculiar about this file. Do not edit the file in any way. Just close it when you are done. (Annoyingly, Excel asks you to save your changes, even if you did not touch anything in the file: why is this cumbersome?) its bright and unreadable colors, data is in wide/tidy format and many columns have the same value on each cell of the column. B. Open the file in R, using the {readxl} package. ce_data &lt;- read_xlsx(here(&quot;1.1_data/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;)) No the data types have not been correctly assigned, column compname could have been the data type factor, and compConcentration should be numeric. D. Create a graph displaying a scatterplot for the CE.LIQ.FLOW.062_Tidydata.xlsx data, for the different compounds and the varying concentrations. Put the compConcentration on the x-axis, the DataRaw counts on the y-axis and assign a colour to each level in compName. Assign a different symbol (shape =) to each level in the expType variable. Try fixing the labels of the x-axis so that we can read them. ce_data$compConcentration &lt;- as.numeric(ce_data$compConcentration) ## Warning: NAs introduced by coercion ce_data$compName &lt;- as_factor(ce_data$compName) ce_data %&gt;% slice_sample(prop = 0.40) %&gt;% ggplot(aes(x = compConcentration, y = RawData)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.3) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 1 rows containing missing values (geom_point). E. When creating the plot under C), what happened with the ordering of the x-axis labels. Explain why this happens. Look at the data-type of the compConcentration column in the data again to find a clue. ce_data &lt;- read_xlsx(here(&quot;1.1_data/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;)) ce_data %&gt;% ggplot(aes(x = compConcentration, y = RawData)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.2) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 5 rows containing missing values (geom_point). class(ce_data$compConcentration) ## [1] &quot;character&quot; The data type of compConcentration is character, this means per concentration value it adds a point on the x-axis. this results in the overplotted mess seen here. F. Correct the data-type of compConcentration to numeric and than look at the graph again. Use a log10 transformation on the x-axis to get a clear graph. Also, add a bit of jitter to the points in the graph so that points are not overlapping. ce_data$compConcentration &lt;- as.numeric(ce_data$compConcentration) ## Warning: NAs introduced by coercion ce_data %&gt;% ggplot(aes(x = log10(compConcentration), y = RawData)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.2) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 6 rows containing missing values (geom_point). G.H. Fill in: (G) The positive control for this experiments is ethanol (H) The negative control for this experiment isS-medium\". I. Think about how you would analyze this experiment to learn whether there is indeed an effect of different concentrations on offspring count and whether the different compounds have a different curve (IC50). Write down your analysis as a step-wise plan I would create dose-response curves based on the data per compound. I would calculate P-values to test if the diffrence between concentrations of a compound has a significant effect on the number of offspring. this would first be done by checking for normality (shapiro wilk and/or q-q plots) then doing a Anova or Friedmans. J. Normalize the data for the controlNegative in such a way that the mean value for controlNegative is exactly equal to 1 and that all other values are expressed as a fraction thereof. Rerun your graphs with the normalized data. #calculating mean of control negative outside of mutate because mutate doesn&#39;t like filter function CN_mean &lt;- ce_data %&gt;% filter(expType == &quot;controlNegative&quot;) %&gt;% select(&quot;RawData&quot;) %&gt;% colMeans() normalized_ce_data &lt;- ce_data %&gt;% mutate(norm_data = RawData/CN_mean) #checking if it&#39;s correct normalized_ce_data %&gt;% group_by(expType) %&gt;% summarise(m = mean(norm_data, na.rm = T)) ## # A tibble: 4 x 2 ## expType m ## &lt;chr&gt; &lt;dbl&gt; ## 1 controlNegative 1 ## 2 controlPositive 0.575 ## 3 controlVehicleA 1.07 ## 4 experiment 0.763 #making first plot normalized_ce_data %&gt;% slice_sample(prop = 0.40) %&gt;% ggplot(aes(x = compConcentration, y = norm_data)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.3) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 5 rows containing missing values (geom_point). #makng the log plot normalized_ce_data %&gt;% ggplot(aes(x = log10(compConcentration), y = norm_data)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.2) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 6 rows containing missing values (geom_point). K. Why would you want to take the step under J? "],["portfolio-assignment-1-2-part-1.html", "2 Portfolio assignment 1.2 part 1", " 2 Portfolio assignment 1.2 part 1 This exercise is about identifying reproducibility issues in a scientific publication. We use the criteria for reproduciblity that are publically available via here. Article used: A retrospective cluster analysis of COVID-19 cases by county *** 2.0.1 Score: Transparency Criteria Definition Score Study Purpose A concise statement in the introduction of the article, often in the last paragraph, that establishes the reason the research was conducted. Also called the study objective. TRUE Data Availability Statement A statement, in an individual section offset from the main body of text, that explains how or if one can access a studys data. The title of the section may vary, but it must explicitly mention data; it is therefore distinct from a supplementary materials section. TRUE Data Location Where the articles data can be accessed, either raw or processed. TRUE Study Location Author has stated in the methods section where the study took place or the datas country/region of origin. TRUE Author Review The professionalism of the contact information that the author has provided in the manuscript. TRUE Ethics Statement A statement within the manuscript indicating any ethical concerns, including the presence of sensitive data. FALSE Funding Statement A statement within the manuscript indicating whether or not the authors received funding for their research. FALSE Code Availability Authors have shared access to the most updated code that they used in their study, including code used for analysis. TRUE 2.0.2 Explanation: At the top of the article the authors names are displayed, with the names of the universities the study at or are part of. Of one of the authors the email is given. This information falls under the author review criteria. this information is sufficient for the goal of open science in this case because email, department and phone number information can be found online for these scientist. however this might not always be the case so the availability of the email address of the paper is appreciated. The article aims to better understand the pattern of outbreaks of COVID-19 within the US. it states this as a study purpose at the end of the introduction paragraph. it then continuous to formulate 3 research questions which further clarifies the study purpose: How many distinct clusters of counties exhibit similar COVID-19 patterns in the time-series of daily confirmed cases? What is the geographic distribution of the counties within each cluster? Are county-level demographic, socioeconomic and political variables associated with the COVID-19 case patterns? the article then starts to give a detailed description of the methods used in the study, it does this in stages. In the paragraph Stage 0: Data Acquisition and Preprocessing, it starts with explaining what the sources are for the data used in the study. this is a example of the criteria data location. However no link was supplied. At further inspection the data used here came from the R package 'COVID-19', And in the references it does specify the date of accessing the data hub. Also the locations of supplementary data that wasnt taken from other sources is listed in the same paragraph. However not all of the links provided work anymore. working_links &lt;- tibble(&quot;Data used&quot; = c(&quot;Rural and Underserved Counties List&quot;, &quot;Population Density&quot;, &quot;Voting Results&quot;, &quot;Governors Party Affiliation&quot;, &quot;Health Variables&quot;, &quot;Region&quot;), &quot;Link Provided&quot; = c(&quot;https://www.consumerfinance.gov/documents/8911/cfpbrural-underserved-list2020.csv&quot;, &quot;https://www2.census.gov/library/publications/2011/compendia/usacounties/excel/LND01.xls&quot;,&quot;https://doi.org/10.7910/DVN/VOQCHQ&quot;,&quot;https://en.wikipedia.org/w/index.php?title=ListofUnitedStatesgovernors&amp;oldid=977828843&quot;,&quot;https://khn.org/news/as-coronavirus-spreadswidely-millionsof-older-americans-live-in-counties-with-no-icu-beds/#lookup&quot;,&quot;https://www.cdc.gov/coordinatedchronic/docs/nccdphp-regions-map.pdf&quot;), &quot;Link working?&quot; = c(F, F, T, T, F, F) ) knitr::kable(working_links) Data used Link Provided Link working? Rural and Underserved Counties List https://www.consumerfinance.gov/documents/8911/cfpbrural-underserved-list2020.csv FALSE Population Density https://www2.census.gov/library/publications/2011/compendia/usacounties/excel/LND01.xls FALSE Voting Results https://doi.org/10.7910/DVN/VOQCHQ TRUE Governors Party Affiliation https://en.wikipedia.org/w/index.php?title=ListofUnitedStatesgovernors&amp;oldid=977828843 TRUE Health Variables https://khn.org/news/as-coronavirus-spreadswidely-millionsof-older-americans-live-in-counties-with-no-icu-beds/#lookup FALSE Region https://www.cdc.gov/coordinatedchronic/docs/nccdphp-regions-map.pdf FALSE This shows how simply providing links to data used isnt enough because the validity of the repository which host the data isnt always guaranteed. but later in the article under Supporting information it also links to a github page. This is a great example of open science because the data location where the data originates from is stated, and a neat collection of data used within the study is given. within this same paragraph it is stated: To capture the progression of disease in the U.S., the number of confirmed COVID-19 cases at the county level from March 1, 2020 through October 24, 2020 was extracted from the COVID-19 data hub [4]. Only data from the contiguous 48 states were included. In this sentence the region of origin of the data is described, thus the criteria Study location has been met. Under acknowledgements is where you would expect there to a funding statement. But it simple states none. hereby it is neither denied or confirmed that this study is funded so this article does not meet the criteria Funding statement. After the references there is supporting information paragraph, which states what program was used (R), the version (4.0.2), and gives a link to a github page, which sadly no longer works. But the user page can be derivated from the link and so the data used (raw and processed) can be accesed. which is why the article meets the criteria Data Availability Statement and Code Availability. Futher more no ethical concerns were raised in the article so it doesnt meet the criteria Ethics Statement. However this considering the way the study was conducted, there was no need for a ethics statement. "],["portfolio-assignment-1-2-part-2.html", "3 Portfolio assignment 1.2 part 2", " 3 Portfolio assignment 1.2 part 2 3.0.0.0.1 H. Using the OSF website, select a project that addresses an aspect of the SARS-Cov-2 virus. 3.0.0.0.2 I. Select a project that has a dataset and R-code shared in the project environment. Project selected: Bats and COVID-19 3.0.0.0.3 J. Have a look at the code. Describe in your own words what the code intents to achieve. it downloads gtrends data for the quary bats and the word bat translated in diffrent langueses in there associated geolocations, for the time period 2016 to 2020. using this it makes figures that outline the correlation between searches about covid-19 and searches about bats. 3.0.0.0.4 K. In terms of readibility of the code, how would you grade (1(very bad)-5(very good)) the code available. i would give it a 4, the code includes comments outlining the function of big code chunks, however the code uses packages and function im not familiar with so it still quite hard to really understand what the code does. 3.0.0.0.5 L. Download the code and the data to a new RStudio project 3.0.0.0.6 M. Run the script or code that is available to reproduce at least 1 figure tv.dat &lt;- read.csv(file=&quot;~/Documents/Research_Projects/Ongoing/BatsCovid/NewAnalysis_Dec2020/Data/Weekly/USTelevision/GDELTBatsUS1620.csv&quot;) tv.dat$date &lt;- ymd(tv.dat$date) tv.dat[61, &quot;date&quot;] &lt;- &quot;2021-01-01&quot; tv.dat[61, &quot;value&quot;] &lt;- NA tv.dat[61, &quot;X&quot;] &lt;- 61 ggplot() + geom_line(data=tv.dat, aes(x=X, y=value), size=0.8, color=&quot;steelblue&quot;, linetype=&quot;solid&quot;) + theme_bw() + scale_x_continuous(breaks=c(1, 13, 25, 37, 49, 61), labels=c(&quot;2016&quot;, &quot;2017&quot;, &quot;2018&quot;, &quot;2019&quot;, &quot;2020&quot;, &quot;2021&quot;)) + theme(axis.text.x = element_text(colour=&quot;black&quot;,size=14,angle=0,hjust=.5,vjust=.5,face=&quot;plain&quot;), axis.text.y = element_text(colour=&quot;black&quot;,size=14,angle=0,hjust=1,vjust=0,face=&quot;plain&quot;), axis.title.x = element_text(colour=&quot;black&quot;,size=12,angle=0,hjust=.5,vjust=.5,face=&quot;plain&quot;), axis.title.y = element_text(colour=&quot;black&quot;,size=12,angle=90,hjust=.5,vjust=.5,face=&quot;plain&quot;), plot.title = element_text(size=22, face=&quot;bold&quot;)) + theme(strip.background =element_rect(fill=&quot;wheat&quot;)) + labs(x=&quot;&quot;, y=&quot;&quot;) + theme(strip.text = element_text(colour = &quot;black&quot;, size=14, face=&quot;bold&quot;)) 3.0.0.0.7 N. When you encounter errors or flaws in the script, try fixing them and record your changes. Errors: Error in file(file, rt) : cannot open the connection changed the filepath so it matches mine. Error in ymd(tv.dat$date) : could not find function ymd. ymd is part of the lubridate package, loaded the lubridate package. library(lubridate) tv.dat &lt;- read.csv(file=(here(&quot;1.2_data/GDELTBatsUS1620.csv&quot;))) tv.dat$date &lt;- ymd(tv.dat$date) tv.dat[61, &quot;date&quot;] &lt;- &quot;2021-01-01&quot; tv.dat[61, &quot;value&quot;] &lt;- NA tv.dat[61, &quot;X&quot;] &lt;- 61 ggplot() + geom_line(data=tv.dat, aes(x=X, y=value), size=0.8, color=&quot;steelblue&quot;, linetype=&quot;solid&quot;) + theme_bw() + scale_x_continuous(breaks=c(1, 13, 25, 37, 49, 61), labels=c(&quot;2016&quot;, &quot;2017&quot;, &quot;2018&quot;, &quot;2019&quot;, &quot;2020&quot;, &quot;2021&quot;)) + theme(axis.text.x = element_text(colour=&quot;black&quot;,size=14,angle=0,hjust=.5,vjust=.5,face=&quot;plain&quot;), axis.text.y = element_text(colour=&quot;black&quot;,size=14,angle=0,hjust=1,vjust=0,face=&quot;plain&quot;), axis.title.x = element_text(colour=&quot;black&quot;,size=12,angle=0,hjust=.5,vjust=.5,face=&quot;plain&quot;), axis.title.y = element_text(colour=&quot;black&quot;,size=12,angle=90,hjust=.5,vjust=.5,face=&quot;plain&quot;), plot.title = element_text(size=22, face=&quot;bold&quot;)) + theme(strip.background =element_rect(fill=&quot;wheat&quot;)) + labs(x=&quot;&quot;, y=&quot;&quot;) + theme(strip.text = element_text(colour = &quot;black&quot;, size=14, face=&quot;bold&quot;)) ## Warning: Removed 1 row(s) containing missing values (geom_path). O. Taken together on a scale from 1 (very hard) to 5 (very easy), how much effort did it take you to reproduce the visualization from the project, report or article. 5 very easy, the code used uses common packages and is very readable. P. Generate an RMarkdown script that contains the details on the project you selected, the code you used to create the visualization and your score for reproducibility. "],["portfolio-assignment-2.html", "4 Portfolio assignment 2", " 4 Portfolio assignment 2 plying the Guerrilla analytics framework to your own project. Look at your RStudio project that you created for the DAUR-II final assignment Rearrange your project according the Guerilla principles explained above Add README files to the datasets Use the {fs} package to share a screenshot of your folder tree in your portfolio, look at: for more info on how to use the {fs} package. B. Now clean up your work environment for this course (workflows) and the parallel course in DSFB2 (projecticum). Set up a folder structure that will accomodate future plans and collaboration on the projecticum. Provide readme-files or comments within the code where needed. dir_tree(&quot;/Users/larsd/Documents/R/DSFB/DAUR2_eindopdracht&quot;, recurse = TRUE) ## /Users/larsd/Documents/R/DSFB/DAUR2_eindopdracht ## +-- DAUR2_eindopdracht.Rproj ## +-- DAUR2_eindopdracht_v1.Rmd ## +-- DAUR2_eindopdracht_v2.Rmd ## +-- DAUR2_eindopdracht_v3.Rmd ## +-- index.Rmd ## +-- supplementory ## | \\-- vragen_eindopdracht_Daniel_Lars[2430].docx ## \\-- _book ## +-- libs ## | +-- anchor-sections-1.0.1 ## | | +-- anchor-sections.css ## | | \\-- anchor-sections.js ## | +-- gitbook-2.6.7 ## | | +-- css ## | | | +-- fontawesome ## | | | | \\-- fontawesome-webfont.ttf ## | | | +-- plugin-bookdown.css ## | | | +-- plugin-clipboard.css ## | | | +-- plugin-fontsettings.css ## | | | +-- plugin-highlight.css ## | | | +-- plugin-search.css ## | | | +-- plugin-table.css ## | | | \\-- style.css ## | | \\-- js ## | | +-- app.min.js ## | | +-- clipboard.min.js ## | | +-- jquery.highlight.js ## | | +-- lunr.js ## | | +-- plugin-bookdown.js ## | | +-- plugin-clipboard.js ## | | +-- plugin-fontsettings.js ## | | +-- plugin-search.js ## | | \\-- plugin-sharing.js ## | +-- header-attrs-2.7 ## | | \\-- header-attrs.js ## | \\-- jquery-2.2.3 ## | \\-- jquery.min.js ## +-- reference-keys.txt ## +-- search_index.json ## \\-- _main.html "],["portfolio-assignment-7.html", "5 Portfolio assignment 7 5.1 1. Load the flu (./data/flu_data.csv), the dengue (./data/dengue_data.csv) and the gapminder ({dslabs} package) into three separate dataframes in R 5.2 2. Check if they are in the right shape. Is the data in the tidy format? If not change the format to tidy 5.3 3. Change the country and date variables of the three tables so that they coincide in terms of data type, class and values 5.4 4. Store the three tables as separate (so six in total) .csv and .rds files. 5.5 5. In Dbeaver create a new PostgreSQL database workflowsdb", " 5 Portfolio assignment 7 5.1 1. Load the flu (./data/flu_data.csv), the dengue (./data/dengue_data.csv) and the gapminder ({dslabs} package) into three separate dataframes in R dengue &lt;- read.csv(here::here(&quot;7_data/dengue_data.txt&quot;), skip = 11) head(dengue) ## Date Argentina Bolivia Brazil India Indonesia Mexico Philippines Singapore Thailand Venezuela ## 1 2002-12-29 NA 0.101 0.073 0.062 0.101 NA NA 0.059 NA NA ## 2 2003-01-05 NA 0.143 0.098 0.047 0.039 NA NA 0.059 NA NA ## 3 2003-01-12 NA 0.176 0.119 0.051 0.059 0.071 NA 0.238 NA NA ## 4 2003-01-19 NA 0.173 0.170 0.032 0.039 0.052 NA 0.175 NA NA ## 5 2003-01-26 NA 0.146 0.138 0.040 0.112 0.048 NA 0.164 NA NA ## 6 2003-02-02 NA 0.160 0.202 0.038 0.049 0.041 NA 0.163 NA NA flu &lt;- read.csv(here::here(&quot;7_data/flu_data.txt&quot;), skip = 11) head(flu) ## Date Argentina Australia Austria Belgium Bolivia Brazil Bulgaria Canada Chile France Germany Hungary Japan Mexico Netherlands ## 1 2002-12-29 NA NA NA NA NA 174 NA NA NA NA NA NA NA NA NA ## 2 2003-01-05 NA NA NA NA NA 162 NA NA NA NA NA NA NA NA NA ## 3 2003-01-12 NA NA NA NA NA 174 NA NA 1 NA NA NA NA NA NA ## 4 2003-01-19 NA NA NA NA NA 162 NA NA 0 NA NA NA NA NA NA ## 5 2003-01-26 NA NA NA NA NA 131 NA NA 0 NA NA NA NA NA NA ## 6 2003-02-02 136 NA NA NA NA 151 NA NA 0 NA NA NA NA NA NA ## New.Zealand Norway Paraguay Peru Poland Romania Russia South.Africa Spain Sweden Switzerland Ukraine United.States Uruguay ## 1 NA NA NA 329 NA NA NA NA NA NA NA NA NA NA ## 2 NA NA NA 315 NA NA NA NA NA NA NA NA NA NA ## 3 NA NA NA 314 NA NA NA NA NA NA NA NA NA NA ## 4 NA NA NA 267 NA NA NA NA NA NA NA NA NA NA ## 5 NA NA NA 241 NA NA NA NA NA NA NA NA NA NA ## 6 NA NA NA 227 NA NA NA NA NA NA NA NA NA NA head(gapminder) ## country year infant_mortality life_expectancy fertility population gdp continent region ## 1 Albania 1960 115.40 62.87 6.19 1636054 NA Europe Southern Europe ## 2 Algeria 1960 148.20 47.50 7.65 11124892 13828152297 Africa Northern Africa ## 3 Angola 1960 208.00 35.98 7.32 5270844 NA Africa Middle Africa ## 4 Antigua and Barbuda 1960 NA 62.97 4.43 54681 NA Americas Caribbean ## 5 Argentina 1960 59.87 65.39 3.11 20619075 108322326649 Americas South America ## 6 Armenia 1960 NA 66.86 4.55 1867396 NA Asia Western Asia 5.2 2. Check if they are in the right shape. Is the data in the tidy format? If not change the format to tidy dengue &lt;- dengue %&gt;% pivot_longer(Argentina:Venezuela, names_to = &quot;country&quot;, values_to = &quot;value&quot;) head(dengue) ## # A tibble: 6 x 3 ## Date country value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2002-12-29 Argentina NA ## 2 2002-12-29 Bolivia 0.101 ## 3 2002-12-29 Brazil 0.073 ## 4 2002-12-29 India 0.062 ## 5 2002-12-29 Indonesia 0.101 ## 6 2002-12-29 Mexico NA flu &lt;- flu %&gt;% pivot_longer(Argentina:Uruguay, names_to = &quot;country&quot;, values_to = &quot;value&quot;) head(flu) ## # A tibble: 6 x 3 ## Date country value ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 2002-12-29 Argentina NA ## 2 2002-12-29 Australia NA ## 3 2002-12-29 Austria NA ## 4 2002-12-29 Belgium NA ## 5 2002-12-29 Bolivia NA ## 6 2002-12-29 Brazil 174 5.3 3. Change the country and date variables of the three tables so that they coincide in terms of data type, class and values dengue &lt;- dengue %&gt;% separate(&quot;Date&quot;, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep = &quot;-&quot;) dengue &lt;- dengue[-c(2,3)] dengue$year &lt;- as.integer(dengue$year) dengue$country &lt;- as.factor(dengue$country) dengue &lt;- dengue %&gt;% group_by(year) %&gt;% summarise(&quot;country&quot; = country, &quot;dengue activity&quot; = sum(value, na.rm = T)) ## `summarise()` has grouped output by &#39;year&#39;. You can override using the `.groups` argument. head(dengue) ## # A tibble: 6 x 3 ## # Groups: year [1] ## year country `dengue activity` ## &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 2002 Argentina 0.396 ## 2 2002 Bolivia 0.396 ## 3 2002 Brazil 0.396 ## 4 2002 India 0.396 ## 5 2002 Indonesia 0.396 ## 6 2002 Mexico 0.396 flu &lt;- flu %&gt;% separate(&quot;Date&quot;, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep = &quot;-&quot;) flu &lt;- flu[-c(2,3)] flu$year &lt;- as.integer(flu$year) flu$country &lt;- as.factor(flu$country) flu &lt;- flu %&gt;% group_by(year) %&gt;% summarise(&quot;country&quot; = country, &quot;influenza activity&quot; = sum(value, na.rm = T)) ## `summarise()` has grouped output by &#39;year&#39;. You can override using the `.groups` argument. flu ## # A tibble: 19,111 x 3 ## # Groups: year [14] ## year country `influenza activity` ## &lt;int&gt; &lt;fct&gt; &lt;int&gt; ## 1 2002 Argentina 503 ## 2 2002 Australia 503 ## 3 2002 Austria 503 ## 4 2002 Belgium 503 ## 5 2002 Bolivia 503 ## 6 2002 Brazil 503 ## 7 2002 Bulgaria 503 ## 8 2002 Canada 503 ## 9 2002 Chile 503 ## 10 2002 France 503 ## # ... with 19,101 more rows 5.4 4. Store the three tables as separate (so six in total) .csv and .rds files. for (x in c(&quot;flu&quot;, &quot;dengue&quot;, &quot;gapminder&quot;)) { filecsv &lt;- paste0(paste0(here(&quot;7_data&quot;, x)), &quot;_tidy.csv&quot;) filerds &lt;- paste0(paste0(here(&quot;7_data&quot;, x)), &quot;_tidy.rds&quot;) write.csv(get(x), file = filecsv) saveRDS(get(x), file = filerds) } 5.5 5. In Dbeaver create a new PostgreSQL database workflowsdb 5.5.1 6. Using RPostgreSQL, insert the tables into the database. con &lt;- dbConnect(RPostgres::Postgres(), dbname = &quot;workflowsdb&quot;, host=&quot;localhost&quot;, port=&quot;5432&quot;, user=&quot;postgres&quot;, password=&quot;NEWkidsweek123&quot;) dbWriteTable(con, &quot;dengue data&quot;, dengue) dbWriteTable(con, &quot;flu data&quot;, flu) dbWriteTable(con, &quot;gapminder data&quot;, gapminder) dbDisconnect(con) Inspect the contents of the tables with SQL (in DBeaver) and save the SQL script. Inspect the contents of the tables with dplyr (in R) and save a RMarkdown showing what you are doing. Load the gapminder data in R and change the dataframe in such as way that you could join it to dengue and flue. Save this clean gapminder data in the workflowsdb database Perform some joins (your choice) with SQL (can be done in DBeaver or with dplyr. Generate a joined table, and export this from the database to R. Show some descriptive statistics with this table, and at least 3 visualisations using ggplot2. show all of your actions in this assignment in a Rmd file, perhaps with pictures and provide text explaining and showcasing your skills. "]]
