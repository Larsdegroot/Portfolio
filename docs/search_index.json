[["portfolio-assignment-1-1.html", "Portfolio of DSFB 1 Portfolio assignment 1.1 1.1 A. Review the following Excel file in the ./data/CE.LIQ.FLOW.062_Tidydata.xlsx (its here), by opening the file in Excel. See if you can spot anything peculiar about this file. Do not edit the file in any way. Just close it when you are done. (Annoyingly, Excel asks you to save your changes, even if you did not touch anything in the file: why is this cumbersome?) 1.2 B. Open the file in R, using the {readxl} package. 1.3 D. Create a graph displaying a scatterplot for the CE.LIQ.FLOW.062_Tidydata.xlsx data, for the different compounds and the varying concentrations. Put the compConcentration on the x-axis, the DataRaw counts on the y-axis and assign a colour to each level in compName. Assign a different symbol (shape =) to each level in the expType variable. Try fixing the labels of the x-axis so that we can read them. 1.4 E. When creating the plot under C), what happened with the ordering of the x-axis labels. Explain why this happens. Look at the data-type of the compConcentration column in the data again to find a clue. 1.5 F. Correct the data-type of compConcentration to numeric and than look at the graph again. Use a log10 transformation on the x-axis to get a clear graph. Also, add a bit of jitter to the points in the graph so that points are not overlapping. 1.6 G.H. Fill in: (G) The positive control for this experiments is ethanol (H) The negative control for this experiment isS-medium\". 1.7 J. Normalize the data for the controlNegative in such a way that the mean value for controlNegative is exactly equal to 1 and that all other values are expressed as a fraction thereof. Rerun your graphs with the normalized data. 1.8 K. Why would you want to take the step under J?", " Portfolio of DSFB Lars de Groot 1 Portfolio assignment 1.1 1.1 A. Review the following Excel file in the ./data/CE.LIQ.FLOW.062_Tidydata.xlsx (its here), by opening the file in Excel. See if you can spot anything peculiar about this file. Do not edit the file in any way. Just close it when you are done. (Annoyingly, Excel asks you to save your changes, even if you did not touch anything in the file: why is this cumbersome?) its bright with unreadable colors. The data is in wide/tidy format and many columns have the same value on each cell of the column. 1.2 B. Open the file in R, using the {readxl} package. ce_data &lt;- read_xlsx(here(&quot;1.1_data/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;)) No the data types have not been correctly assigned, column compname could have been the data type factor, and compConcentration should be numeric. 1.3 D. Create a graph displaying a scatterplot for the CE.LIQ.FLOW.062_Tidydata.xlsx data, for the different compounds and the varying concentrations. Put the compConcentration on the x-axis, the DataRaw counts on the y-axis and assign a colour to each level in compName. Assign a different symbol (shape =) to each level in the expType variable. Try fixing the labels of the x-axis so that we can read them. ce_data$compConcentration &lt;- as.numeric(ce_data$compConcentration) ## Warning: NAs introduced by coercion ce_data$compName &lt;- as_factor(ce_data$compName) ce_data %&gt;% slice_sample(prop = 0.40) %&gt;% ggplot(aes(x = compConcentration, y = RawData)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.3) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 2 rows containing missing values (geom_point). 1.4 E. When creating the plot under C), what happened with the ordering of the x-axis labels. Explain why this happens. Look at the data-type of the compConcentration column in the data again to find a clue. ce_data &lt;- read_xlsx(here(&quot;1.1_data/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;)) ce_data %&gt;% ggplot(aes(x = compConcentration, y = RawData)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.2) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 5 rows containing missing values (geom_point). class(ce_data$compConcentration) ## [1] &quot;character&quot; The data type of compConcentration is character, this means per concentration value it adds a point on the x-axis. this results in the overplotted mess seen here. 1.5 F. Correct the data-type of compConcentration to numeric and than look at the graph again. Use a log10 transformation on the x-axis to get a clear graph. Also, add a bit of jitter to the points in the graph so that points are not overlapping. ce_data$compConcentration &lt;- as.numeric(ce_data$compConcentration) ## Warning: NAs introduced by coercion ce_data %&gt;% ggplot(aes(x = log10(compConcentration), y = RawData)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.2) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 6 rows containing missing values (geom_point). 1.6 G.H. Fill in: (G) The positive control for this experiments is ethanol (H) The negative control for this experiment isS-medium\". I. Think about how you would analyze this experiment to learn whether there is indeed an effect of different concentrations on offspring count and whether the different compounds have a different curve (IC50). Write down your analysis as a step-wise plan I would create dose-response curves based on the data per compound. I would calculate P-values to test if the diffrence between concentrations of a compound has a significant effect on the number of offspring. this would first be done by checking for normality (shapiro wilk and/or q-q plots) then doing a Anova or Friedmans. 1.7 J. Normalize the data for the controlNegative in such a way that the mean value for controlNegative is exactly equal to 1 and that all other values are expressed as a fraction thereof. Rerun your graphs with the normalized data. #calculating mean of control negative outside of mutate because mutate doesn&#39;t like filter function CN_mean &lt;- ce_data %&gt;% filter(expType == &quot;controlNegative&quot;) %&gt;% select(&quot;RawData&quot;) %&gt;% colMeans() normalized_ce_data &lt;- ce_data %&gt;% mutate(norm_data = RawData/CN_mean) #checking if it&#39;s correct normalized_ce_data %&gt;% group_by(expType) %&gt;% summarise(m = mean(norm_data, na.rm = T)) ## # A tibble: 4 x 2 ## expType m ## &lt;chr&gt; &lt;dbl&gt; ## 1 controlNegative 1 ## 2 controlPositive 0.575 ## 3 controlVehicleA 1.07 ## 4 experiment 0.763 #making first plot normalized_ce_data %&gt;% slice_sample(prop = 0.40) %&gt;% ggplot(aes(x = compConcentration, y = norm_data)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.3) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 2 rows containing missing values (geom_point). #makng the log plot normalized_ce_data %&gt;% ggplot(aes(x = log10(compConcentration), y = norm_data)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.2) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 6 rows containing missing values (geom_point). 1.8 K. Why would you want to take the step under J? this eliminates natural and extraneous variation between groups. After normalization all groups fall on the same scale of 0 - 1. "],["portfolio-assignment-1-2-part-1.html", "2 Portfolio assignment 1.2 part 1 2.1 Score: 2.2 Explanation:", " 2 Portfolio assignment 1.2 part 1 This exercise is about identifying reproducibility issues in a scientific publication. We use the criteria for reproduciblity that are publically available via here. Article used: A retrospective cluster analysis of COVID-19 cases by county *** 2.1 Score: Transparency Criteria Definition Score Study Purpose A concise statement in the introduction of the article, often in the last paragraph, that establishes the reason the research was conducted. Also called the study objective. TRUE Data Availability Statement A statement, in an individual section offset from the main body of text, that explains how or if one can access a studys data. The title of the section may vary, but it must explicitly mention data; it is therefore distinct from a supplementary materials section. TRUE Data Location Where the articles data can be accessed, either raw or processed. TRUE Study Location Author has stated in the methods section where the study took place or the datas country/region of origin. TRUE Author Review The professionalism of the contact information that the author has provided in the manuscript. TRUE Ethics Statement A statement within the manuscript indicating any ethical concerns, including the presence of sensitive data. FALSE Funding Statement A statement within the manuscript indicating whether or not the authors received funding for their research. FALSE Code Availability Authors have shared access to the most updated code that they used in their study, including code used for analysis. TRUE 2.2 Explanation: At the top of the article the authors names are displayed, with the names of the universities the study at or are part of. Of one of the authors the email is given. This information falls under the author review criteria. this information is sufficient for the goal of open science in this case because email, department and phone number information can be found online for these scientist. however this might not always be the case so the availability of the email address of the paper is appreciated. The article aims to better understand the pattern of outbreaks of COVID-19 within the US. it states this as a study purpose at the end of the introduction paragraph. it then continuous to formulate 3 research questions which further clarifies the study purpose: How many distinct clusters of counties exhibit similar COVID-19 patterns in the time-series of daily confirmed cases? What is the geographic distribution of the counties within each cluster? Are county-level demographic, socioeconomic and political variables associated with the COVID-19 case patterns? the article then starts to give a detailed description of the methods used in the study, it does this in stages. In the paragraph Stage 0: Data Acquisition and Preprocessing, it starts with explaining what the sources are for the data used in the study. this is a example of the criteria data location. However no link was supplied. At further inspection the data used here came from the R package 'COVID-19', And in the references it does specify the date of accessing the data hub. Also the locations of supplementary data that wasnt taken from other sources is listed in the same paragraph. However not all of the links provided work anymore. working_links &lt;- tibble(&quot;Data used&quot; = c(&quot;Rural and Underserved Counties List&quot;, &quot;Population Density&quot;, &quot;Voting Results&quot;, &quot;Governors Party Affiliation&quot;, &quot;Health Variables&quot;, &quot;Region&quot;), &quot;Link Provided&quot; = c(&quot;https://www.consumerfinance.gov/documents/8911/cfpbrural-underserved-list2020.csv&quot;, &quot;https://www2.census.gov/library/publications/2011/compendia/usacounties/excel/LND01.xls&quot;,&quot;https://doi.org/10.7910/DVN/VOQCHQ&quot;,&quot;https://en.wikipedia.org/w/index.php?title=ListofUnitedStatesgovernors&amp;oldid=977828843&quot;,&quot;https://khn.org/news/as-coronavirus-spreadswidely-millionsof-older-americans-live-in-counties-with-no-icu-beds/#lookup&quot;,&quot;https://www.cdc.gov/coordinatedchronic/docs/nccdphp-regions-map.pdf&quot;), &quot;Link working?&quot; = c(F, F, T, T, F, F) ) knitr::kable(working_links) Data used Link Provided Link working? Rural and Underserved Counties List https://www.consumerfinance.gov/documents/8911/cfpbrural-underserved-list2020.csv FALSE Population Density https://www2.census.gov/library/publications/2011/compendia/usacounties/excel/LND01.xls FALSE Voting Results https://doi.org/10.7910/DVN/VOQCHQ TRUE Governors Party Affiliation https://en.wikipedia.org/w/index.php?title=ListofUnitedStatesgovernors&amp;oldid=977828843 TRUE Health Variables https://khn.org/news/as-coronavirus-spreadswidely-millionsof-older-americans-live-in-counties-with-no-icu-beds/#lookup FALSE Region https://www.cdc.gov/coordinatedchronic/docs/nccdphp-regions-map.pdf FALSE This shows how simply providing links to data used isnt enough because the validity of the repository which host the data isnt always guaranteed. but later in the article under Supporting information it also links to a github page. This is a great example of open science because the data location where the data originates from is stated, and a neat collection of data used within the study is given. within this same paragraph it is stated: To capture the progression of disease in the U.S., the number of confirmed COVID-19 cases at the county level from March 1, 2020 through October 24, 2020 was extracted from the COVID-19 data hub [4]. Only data from the contiguous 48 states were included. In this sentence the region of origin of the data is described, thus the criteria Study location has been met. Under acknowledgements is where you would expect there to a funding statement. But it simple states none. hereby it is neither denied or confirmed that this study is funded so this article does not meet the criteria Funding statement. After the references there is supporting information paragraph, which states what program was used (R), the version (4.0.2), and gives a link to a github page, which sadly no longer works. But the user page can be derivated from the link and so the data used (raw and processed) can be accesed. which is why the article meets the criteria Data Availability Statement and Code Availability. Futher more no ethical concerns were raised in the article so it doesnt meet the criteria Ethics Statement. However this considering the way the study was conducted, there was no need for a ethics statement. "],["portfolio-assignment-1-2-part-2.html", "3 Portfolio assignment 1.2 part 2 3.1 H. Using the OSF website, select a project that addresses an aspect of the SARS-Cov-2 virus. 3.2 I. Select a project that has a dataset and R-code shared in the project environment. 3.3 J. Have a look at the code. Describe in your own words what the code intents to achieve. 3.4 K. In terms of readibility of the code, how would you grade (1(very bad)-5(very good)) the code available. 3.5 L. Download the code and the data to a new RStudio project M. Run the script or code that is available to reproduce at least 1 figure 3.6 N. When you encounter errors or flaws in the script, try fixing them and record your changes. 3.7 O. Taken together on a scale from 1 (very hard) to 5 (very easy), how much effort did it take you to reproduce the visualization from the project, report or article. 3.8 P. Generate an RMarkdown script that contains the details on the project you selected, the code you used to create the visualization and your score for reproducibility.", " 3 Portfolio assignment 1.2 part 2 3.1 H. Using the OSF website, select a project that addresses an aspect of the SARS-Cov-2 virus. 3.2 I. Select a project that has a dataset and R-code shared in the project environment. Project selected: Bats and COVID-19 3.3 J. Have a look at the code. Describe in your own words what the code intents to achieve. it downloads gtrends data for the quary bats and the word bat translated in diffrent langueses in there associated geolocations, for the time period 2016 to 2020. using this it makes figures that outline the correlation between searches about covid-19 and searches about bats. 3.4 K. In terms of readibility of the code, how would you grade (1(very bad)-5(very good)) the code available. i would give it a 4, the code includes comments outlining the function of big code chunks, however the code uses packages and function im not familiar with so it still quite hard to really understand what the code does. 3.5 L. Download the code and the data to a new RStudio project M. Run the script or code that is available to reproduce at least 1 figure tv.dat &lt;- read.csv(file=&quot;~/Documents/Research_Projects/Ongoing/BatsCovid/NewAnalysis_Dec2020/Data/Weekly/USTelevision/GDELTBatsUS1620.csv&quot;) tv.dat$date &lt;- ymd(tv.dat$date) tv.dat[61, &quot;date&quot;] &lt;- &quot;2021-01-01&quot; tv.dat[61, &quot;value&quot;] &lt;- NA tv.dat[61, &quot;X&quot;] &lt;- 61 ggplot() + geom_line(data=tv.dat, aes(x=X, y=value), size=0.8, color=&quot;steelblue&quot;, linetype=&quot;solid&quot;) + theme_bw() + scale_x_continuous(breaks=c(1, 13, 25, 37, 49, 61), labels=c(&quot;2016&quot;, &quot;2017&quot;, &quot;2018&quot;, &quot;2019&quot;, &quot;2020&quot;, &quot;2021&quot;)) + theme(axis.text.x = element_text(colour=&quot;black&quot;,size=14,angle=0,hjust=.5,vjust=.5,face=&quot;plain&quot;), axis.text.y = element_text(colour=&quot;black&quot;,size=14,angle=0,hjust=1,vjust=0,face=&quot;plain&quot;), axis.title.x = element_text(colour=&quot;black&quot;,size=12,angle=0,hjust=.5,vjust=.5,face=&quot;plain&quot;), axis.title.y = element_text(colour=&quot;black&quot;,size=12,angle=90,hjust=.5,vjust=.5,face=&quot;plain&quot;), plot.title = element_text(size=22, face=&quot;bold&quot;)) + theme(strip.background =element_rect(fill=&quot;wheat&quot;)) + labs(x=&quot;&quot;, y=&quot;&quot;) + theme(strip.text = element_text(colour = &quot;black&quot;, size=14, face=&quot;bold&quot;)) 3.6 N. When you encounter errors or flaws in the script, try fixing them and record your changes. Errors: Error in file(file, rt) : cannot open the connection changed the filepath so it matches mine. Error in ymd(tv.dat$date) : could not find function ymd. ymd is part of the lubridate package, loaded the lubridate package. library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union tv.dat &lt;- read.csv(file=(here(&quot;1.2_data/GDELTBatsUS1620.csv&quot;))) tv.dat$date &lt;- ymd(tv.dat$date) tv.dat[61, &quot;date&quot;] &lt;- &quot;2021-01-01&quot; tv.dat[61, &quot;value&quot;] &lt;- NA tv.dat[61, &quot;X&quot;] &lt;- 61 ggplot() + geom_line(data=tv.dat, aes(x=X, y=value), size=0.8, color=&quot;steelblue&quot;, linetype=&quot;solid&quot;) + theme_bw() + scale_x_continuous(breaks=c(1, 13, 25, 37, 49, 61), labels=c(&quot;2016&quot;, &quot;2017&quot;, &quot;2018&quot;, &quot;2019&quot;, &quot;2020&quot;, &quot;2021&quot;)) + theme(axis.text.x = element_text(colour=&quot;black&quot;,size=14,angle=0,hjust=.5,vjust=.5,face=&quot;plain&quot;), axis.text.y = element_text(colour=&quot;black&quot;,size=14,angle=0,hjust=1,vjust=0,face=&quot;plain&quot;), axis.title.x = element_text(colour=&quot;black&quot;,size=12,angle=0,hjust=.5,vjust=.5,face=&quot;plain&quot;), axis.title.y = element_text(colour=&quot;black&quot;,size=12,angle=90,hjust=.5,vjust=.5,face=&quot;plain&quot;), plot.title = element_text(size=22, face=&quot;bold&quot;)) + theme(strip.background =element_rect(fill=&quot;wheat&quot;)) + labs(x=&quot;&quot;, y=&quot;&quot;) + theme(strip.text = element_text(colour = &quot;black&quot;, size=14, face=&quot;bold&quot;)) ## Warning: Removed 1 row(s) containing missing values (geom_path). 3.7 O. Taken together on a scale from 1 (very hard) to 5 (very easy), how much effort did it take you to reproduce the visualization from the project, report or article. 5 very easy, the code used uses common packages and is very readable. 3.8 P. Generate an RMarkdown script that contains the details on the project you selected, the code you used to create the visualization and your score for reproducibility. "],["portfolio-assignment-2.html", "4 Portfolio assignment 2", " 4 Portfolio assignment 2 Applying the Guerrilla analytics framework to your own project. Look at your RStudio project that you created for the DAUR-II final assignment Rearrange your project according the Guerilla principles explained above Add README files to the datasets Use the {fs} package to share a screenshot of your folder tree in your portfolio, look at: for more info on how to use the {fs} package. B. Now clean up your work environment for this course (workflows) and the parallel course in DSFB2 (projecticum). Set up a folder structure that will accomodate future plans and collaboration on the projecticum. Provide readme-files or comments within the code where needed. dir_tree(&quot;/Users/larsd/Documents/R/DSFB/DAUR2_eindopdracht&quot;, recurse = TRUE) ## /Users/larsd/Documents/R/DSFB/DAUR2_eindopdracht ## +-- DAUR2_eindopdracht.Rproj ## +-- DAUR2_eindopdracht_v1.Rmd ## +-- DAUR2_eindopdracht_v2.Rmd ## +-- DAUR2_eindopdracht_v3.Rmd ## +-- DAUR2_eindopdracht_v4.Rmd ## +-- DAUR2_eindopdracht_v5.Rmd ## +-- DAUR2_eindopdracht_v6.Rmd ## +-- DAUR2_eindopdracht_v7.Rmd ## +-- images ## | \\-- seqalignmentv6.jpeg ## +-- index.Rmd ## +-- rsconnect ## | \\-- documents ## | \\-- index.Rmd ## | \\-- bookdown.org ## | \\-- larsdgsp ## | \\-- DAUR2_eindopdracht.dcf ## +-- supplementory ## | \\-- vragen_eindopdracht_Daniel_Lars[2430].docx ## +-- _book ## | +-- images ## | | \\-- seqalignmentv6.jpeg ## | +-- libs ## | | +-- anchor-sections-1.0.1 ## | | | +-- anchor-sections.css ## | | | \\-- anchor-sections.js ## | | +-- gitbook-2.6.7 ## | | | +-- css ## | | | | +-- fontawesome ## | | | | | \\-- fontawesome-webfont.ttf ## | | | | +-- plugin-bookdown.css ## | | | | +-- plugin-clipboard.css ## | | | | +-- plugin-fontsettings.css ## | | | | +-- plugin-highlight.css ## | | | | +-- plugin-search.css ## | | | | +-- plugin-table.css ## | | | | \\-- style.css ## | | | \\-- js ## | | | +-- app.min.js ## | | | +-- clipboard.min.js ## | | | +-- jquery.highlight.js ## | | | +-- lunr.js ## | | | +-- plugin-bookdown.js ## | | | +-- plugin-clipboard.js ## | | | +-- plugin-fontsettings.js ## | | | +-- plugin-search.js ## | | | \\-- plugin-sharing.js ## | | +-- header-attrs-2.8 ## | | | \\-- header-attrs.js ## | | +-- jquery-2.2.3 ## | | | \\-- jquery.min.js ## | | +-- kePrint-0.0.1 ## | | | \\-- kePrint.js ## | | \\-- lightable-0.0.1 ## | | \\-- lightable.css ## | +-- reference-keys.txt ## | +-- search_index.json ## | +-- section.html ## | +-- vraag-1-finding-nemo.html ## | +-- vraag-2-lion-king.html ## | +-- vraag3-diabetes.html ## | +-- vraag4-sars-cov-19-virus.html ## | +-- vraag5-cpg-islands.html ## | +-- vraag6-hox-genes.html ## | +-- vraag7-airway.html ## | \\-- _main_files ## | \\-- figure-html ## | +-- berekening-1.png ## | +-- onderzoeksvraag 2-1.png ## | +-- onderzoeksvraag 2-2.png ## | +-- unnamed-chunk-10-1.png ## | +-- unnamed-chunk-12-1.png ## | +-- unnamed-chunk-13-1.png ## | +-- vraag 5_d-1.png ## | \\-- vraag 5_e2-1.png ## \\-- _bookdown_files ## +-- _main_cache ## | \\-- html ## | +-- data install_4c48a4715893e487cd83eea600fd62a5.RData ## | +-- data install_4c48a4715893e487cd83eea600fd62a5.rdb ## | +-- data install_4c48a4715893e487cd83eea600fd62a5.rdx ## | +-- vraag 1_c471dc67424cb02aa57f382a46ab702d.RData ## | +-- vraag 1_c471dc67424cb02aa57f382a46ab702d.rdb ## | +-- vraag 1_c471dc67424cb02aa57f382a46ab702d.rdx ## | \\-- __packages ## \\-- _main_files ## \\-- figure-html ## +-- berekening-1.png ## +-- onderzoeksvraag 2-1.png ## +-- onderzoeksvraag 2-2.png ## +-- unnamed-chunk-10-1.png ## +-- unnamed-chunk-12-1.png ## +-- unnamed-chunk-13-1.png ## +-- unnamed-chunk-9-1.png ## +-- vraag 5_d-1.png ## \\-- vraag 5_e2-1.png "],["portfolio-assignment-5-b.html", "5 Portfolio assignment 5.B 5.1 1. Make a new folder within Mendeley for the projecticum. Place all pdfs you used till now in your folder (if you did not use any papers as source yet, find 3 papers on Pubmed now that you could use for your introduction.). Copy your .bib file to the folder on your computer you are using for the Projecticum git repo. 5.2 2. Start a .Rmd named introduction.Rmd with a few lines introduction on your projecticum topic. 5.3 3. Include automatic inline references to the papers you used. 5.4 4. The bibliography will be placed at the end of the document. Provide an appropriate header. 5.5 5. Merge your work with that of your projecticum partner through github. Solve all the problems you encounter. If github does not want to merge .bib files and you want a merged one, try here. 5.6 6. Find out how you can add websites as reference to Mendeley. 5.7 7. Write (so not copy!) at least 500 words of introduction for your projecticum project and use at least 5 references.", " 5 Portfolio assignment 5.B 5.1 1. Make a new folder within Mendeley for the projecticum. Place all pdfs you used till now in your folder (if you did not use any papers as source yet, find 3 papers on Pubmed now that you could use for your introduction.). Copy your .bib file to the folder on your computer you are using for the Projecticum git repo. Ive searched for 3 paper about how Python is used within the field of bioinformatics. ive also used Refworks because thats the citation manager i use. Our projecticum doesnt require a literature study https://www.longdom.org/scholarly/python-for-bioinformatics--journals-articles-ppts-list-2878.html https://snakemake.readthedocs.io/en/stable/ 5.2 2. Start a .Rmd named introduction.Rmd with a few lines introduction on your projecticum topic. 5.3 3. Include automatic inline references to the papers you used. 5.4 4. The bibliography will be placed at the end of the document. Provide an appropriate header. 5.5 5. Merge your work with that of your projecticum partner through github. Solve all the problems you encounter. If github does not want to merge .bib files and you want a merged one, try here. 5.6 6. Find out how you can add websites as reference to Mendeley. 5.7 7. Write (so not copy!) at least 500 words of introduction for your projecticum project and use at least 5 references. this wont be an introduction but more of a summary "],["portfolio-assignment-7.html", "6 Portfolio assignment 7 6.1 1. Load the flu (./data/flu_data.csv), the dengue (./data/dengue_data.csv) and the gapminder ({dslabs} package) into three separate dataframes in R 6.2 2. Check if they are in the right shape. Is the data in the tidy format? If not change the format to tidy 6.3 3. Change the country and date variables of the three tables so that they coincide in terms of data type, class and values 6.4 4. Store the three tables as separate (so six in total) .csv and .rds files. 6.5 5. In Dbeaver create a new PostgreSQL database workflowsdb 6.6 6. Using RPostgreSQL, insert the tables into the database. 6.7 7. Inspect the contents of the tables with SQL (in DBeaver) and save the SQL script. 6.8 8. Inspect the contents of the tables with dplyr (in R) and save a RMarkdown showing what you are doing. 6.9 9. Load the gapminder data in R and change the dataframe in such as way that you could join it to dengue and flue. 6.10 10. Save this clean gapminder data in the workflowsdb database 6.11 11. Perform some joins (your choice) with SQL (can be done in DBeaver or with dplyr). 6.12 12. Generate a joined table, and export this from the database to R. 6.13 13. Show some descriptive statistics with this table, and at least 3 visualisations using ggplot2.", " 6 Portfolio assignment 7 source(here(&quot;src/port_src7.R&quot;)) ## [1] &quot;A1&quot; &quot;A2&quot; &quot;A3&quot; 6.1 1. Load the flu (./data/flu_data.csv), the dengue (./data/dengue_data.csv) and the gapminder ({dslabs} package) into three separate dataframes in R dengue &lt;- read.csv(here::here(&quot;7_data/dengue_data.txt&quot;), skip = 11) head(dengue) ## Date Argentina Bolivia Brazil India Indonesia Mexico Philippines Singapore Thailand Venezuela ## 1 2002-12-29 NA 0.101 0.073 0.062 0.101 NA NA 0.059 NA NA ## 2 2003-01-05 NA 0.143 0.098 0.047 0.039 NA NA 0.059 NA NA ## 3 2003-01-12 NA 0.176 0.119 0.051 0.059 0.071 NA 0.238 NA NA ## 4 2003-01-19 NA 0.173 0.170 0.032 0.039 0.052 NA 0.175 NA NA ## 5 2003-01-26 NA 0.146 0.138 0.040 0.112 0.048 NA 0.164 NA NA ## 6 2003-02-02 NA 0.160 0.202 0.038 0.049 0.041 NA 0.163 NA NA flu &lt;- read.csv(here::here(&quot;7_data/flu_data.txt&quot;), skip = 11) head(flu) ## Date Argentina Australia Austria Belgium Bolivia Brazil Bulgaria Canada Chile France Germany Hungary Japan Mexico ## 1 2002-12-29 NA NA NA NA NA 174 NA NA NA NA NA NA NA NA ## 2 2003-01-05 NA NA NA NA NA 162 NA NA NA NA NA NA NA NA ## 3 2003-01-12 NA NA NA NA NA 174 NA NA 1 NA NA NA NA NA ## 4 2003-01-19 NA NA NA NA NA 162 NA NA 0 NA NA NA NA NA ## 5 2003-01-26 NA NA NA NA NA 131 NA NA 0 NA NA NA NA NA ## 6 2003-02-02 136 NA NA NA NA 151 NA NA 0 NA NA NA NA NA ## Netherlands New.Zealand Norway Paraguay Peru Poland Romania Russia South.Africa Spain Sweden Switzerland Ukraine ## 1 NA NA NA NA 329 NA NA NA NA NA NA NA NA ## 2 NA NA NA NA 315 NA NA NA NA NA NA NA NA ## 3 NA NA NA NA 314 NA NA NA NA NA NA NA NA ## 4 NA NA NA NA 267 NA NA NA NA NA NA NA NA ## 5 NA NA NA NA 241 NA NA NA NA NA NA NA NA ## 6 NA NA NA NA 227 NA NA NA NA NA NA NA NA ## United.States Uruguay ## 1 NA NA ## 2 NA NA ## 3 NA NA ## 4 NA NA ## 5 NA NA ## 6 NA NA head(gapminder) ## country year infant_mortality life_expectancy fertility population gdp continent region ## 1 Albania 1960 115.40 62.87 6.19 1636054 NA Europe Southern Europe ## 2 Algeria 1960 148.20 47.50 7.65 11124892 13828152297 Africa Northern Africa ## 3 Angola 1960 208.00 35.98 7.32 5270844 NA Africa Middle Africa ## 4 Antigua and Barbuda 1960 NA 62.97 4.43 54681 NA Americas Caribbean ## 5 Argentina 1960 59.87 65.39 3.11 20619075 108322326649 Americas South America ## 6 Armenia 1960 NA 66.86 4.55 1867396 NA Asia Western Asia 6.2 2. Check if they are in the right shape. Is the data in the tidy format? If not change the format to tidy dengue &lt;- dengue %&gt;% pivot_longer(Argentina:Venezuela, names_to = &quot;country&quot;, values_to = &quot;value&quot;) head(dengue) ## # A tibble: 6 x 3 ## Date country value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2002-12-29 Argentina NA ## 2 2002-12-29 Bolivia 0.101 ## 3 2002-12-29 Brazil 0.073 ## 4 2002-12-29 India 0.062 ## 5 2002-12-29 Indonesia 0.101 ## 6 2002-12-29 Mexico NA flu &lt;- flu %&gt;% pivot_longer(Argentina:Uruguay, names_to = &quot;country&quot;, values_to = &quot;value&quot;) head(flu) ## # A tibble: 6 x 3 ## Date country value ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 2002-12-29 Argentina NA ## 2 2002-12-29 Australia NA ## 3 2002-12-29 Austria NA ## 4 2002-12-29 Belgium NA ## 5 2002-12-29 Bolivia NA ## 6 2002-12-29 Brazil 174 6.3 3. Change the country and date variables of the three tables so that they coincide in terms of data type, class and values dengue &lt;- dengue %&gt;% separate(&quot;Date&quot;, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep = &quot;-&quot;) dengue &lt;- dengue[-c(2,3)] dengue$year &lt;- as.integer(dengue$year) dengue$country &lt;- as.factor(dengue$country) dengue &lt;- dengue %&gt;% group_by(year, country) %&gt;% summarise(&quot;country&quot; = country, &quot;dengue_activity&quot; = sum(value, na.rm = T)) %&gt;% unique() ## `summarise()` has grouped output by &#39;year&#39;, &#39;country&#39;. You can override using the `.groups` argument. head(dengue) ## # A tibble: 6 x 3 ## # Groups: year, country [6] ## year country dengue_activity ## &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 2002 Argentina 0 ## 2 2002 Bolivia 0.101 ## 3 2002 Brazil 0.073 ## 4 2002 India 0.062 ## 5 2002 Indonesia 0.101 ## 6 2002 Mexico 0 flu &lt;- flu %&gt;% separate(&quot;Date&quot;, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep = &quot;-&quot;) flu &lt;- flu[-c(2,3)] flu$year &lt;- as.integer(flu$year) flu$country &lt;- as.factor(flu$country) flu &lt;- flu %&gt;% group_by(year, country) %&gt;% summarise(&quot;country&quot; = country, &quot;influenza_activity&quot; = sum(value, na.rm = T)) %&gt;% unique() ## `summarise()` has grouped output by &#39;year&#39;, &#39;country&#39;. You can override using the `.groups` argument. head(flu) ## # A tibble: 6 x 3 ## # Groups: year, country [6] ## year country influenza_activity ## &lt;int&gt; &lt;fct&gt; &lt;int&gt; ## 1 2002 Argentina 0 ## 2 2002 Australia 0 ## 3 2002 Austria 0 ## 4 2002 Belgium 0 ## 5 2002 Bolivia 0 ## 6 2002 Brazil 174 6.4 4. Store the three tables as separate (so six in total) .csv and .rds files. for (x in c(&quot;flu&quot;, &quot;dengue&quot;, &quot;gapminder&quot;)) { export(get(x), path = paste0(here(&quot;7_data//&quot;), x)) } 6.5 5. In Dbeaver create a new PostgreSQL database workflowsdb knitr::include_graphics(here(&quot;7_data/workflowsdb_in_Dbeaver.JPG&quot;)) Figure 6.1: The workflows database in Dbeaver. Workflows database in DBeaver 6.6 6. Using RPostgreSQL, insert the tables into the database. psswd &lt;- .rs.askForPassword(&quot;Database Password:&quot;) con &lt;- dbConnect(RPostgres::Postgres(), dbname = &quot;workflowsdb&quot;, host=&quot;localhost&quot;, port=&quot;5432&quot;, user=&quot;postgres&quot;, password=psswd) dbWriteTable(con, &quot;dengueDB&quot;, dengue, overwrite = T) dbWriteTable(con, &quot;fluDB&quot;, flu, overwrite = T) dbWriteTable(con, &quot;gapminderDB&quot;, gapminder, overwrite = T) 6.7 7. Inspect the contents of the tables with SQL (in DBeaver) and save the SQL script. SELECT * FROM &quot;dengueDB&quot;; Table 6.1: Displaying records 1 - 10 year country dengue_activity 2002 Argentina 0.000 2002 Bolivia 0.101 2002 Brazil 0.073 2002 India 0.062 2002 Indonesia 0.101 2002 Mexico 0.000 2002 Philippines 0.000 2002 Singapore 0.059 2002 Thailand 0.000 2002 Venezuela 0.000 SELECT * FROM &quot;fluDB&quot;; Table 6.2: Displaying records 1 - 10 year country influenza_activity 2002 Argentina 0 2002 Australia 0 2002 Austria 0 2002 Belgium 0 2002 Bolivia 0 2002 Brazil 174 2002 Bulgaria 0 2002 Canada 0 2002 Chile 0 2002 France 0 SELECT * FROM &quot;gapminderDB&quot;; Table 6.3: Displaying records 1 - 10 country year infant_mortality life_expectancy fertility population gdp continent region Albania 1960 115.40 62.87 6.19 1636054 NA Europe Southern Europe Algeria 1960 148.20 47.50 7.65 11124892 13828152297 Africa Northern Africa Angola 1960 208.00 35.98 7.32 5270844 NA Africa Middle Africa Antigua and Barbuda 1960 NA 62.97 4.43 54681 NA Americas Caribbean Argentina 1960 59.87 65.39 3.11 20619075 108322326649 Americas South America Armenia 1960 NA 66.86 4.55 1867396 NA Asia Western Asia Aruba 1960 NA 65.66 4.82 54208 NA Americas Caribbean Australia 1960 20.30 70.87 3.45 10292328 96677859364 Oceania Australia and New Zealand Austria 1960 37.30 68.75 2.70 7065525 52392699681 Europe Western Europe Azerbaijan 1960 NA 61.33 5.57 3897889 NA Asia Western Asia 6.8 8. Inspect the contents of the tables with dplyr (in R) and save a RMarkdown showing what you are doing. db_names &lt;- c(&quot;fluDB&quot;, &quot;dengueDB&quot;, &quot;gapminderDB&quot;) tables &lt;- list() for (i in db_names){ tables[[paste(i)]] &lt;- dbReadTable(con, i) } general_inspection(tables$fluDB, tables$fluDB$year, tables$fluDB$influenza_activity) ## [1] &quot;The data frame tables$fluDB has 3 columns: year, country, influenza_activity&quot; ## [1] &quot;And 406 rows&quot; ## year country influenza_activity ## Min. :2002 Length:406 Min. : 0 ## 1st Qu.:2005 Class :character 1st Qu.: 1696 ## Median :2008 Mode :character Median : 6772 ## Mean :2008 Mean : 20147 ## 3rd Qu.:2012 3rd Qu.: 24975 ## Max. :2015 Max. :155577 general_inspection(tables$dengueDB, tables$dengueDB$year, tables$dengueDB$dengue_activity) ## [1] &quot;The data frame tables$dengueDB has 3 columns: year, country, dengue_activity&quot; ## [1] &quot;And 140 rows&quot; ## year country dengue_activity ## Min. :2002 Length:140 Min. : 0.000 ## 1st Qu.:2005 Class :character 1st Qu.: 2.346 ## Median :2008 Mode :character Median : 5.556 ## Mean :2008 Mean : 6.217 ## 3rd Qu.:2012 3rd Qu.: 8.824 ## Max. :2015 Max. :27.847 general_inspection(tables$gapminderDB) ## [1] &quot;The data frame tables$gapminderDB has 9 columns: country, year, infant_mortality, life_expectancy, fertility, population, gdp, continent, region&quot; ## [1] &quot;And 10545 rows&quot; ## country year infant_mortality life_expectancy fertility population ## Length:10545 Min. :1960 Min. : 1.50 Min. :13.20 Min. :0.840 Min. :3.124e+04 ## Class :character 1st Qu.:1974 1st Qu.: 16.00 1st Qu.:57.50 1st Qu.:2.200 1st Qu.:1.333e+06 ## Mode :character Median :1988 Median : 41.50 Median :67.54 Median :3.750 Median :5.009e+06 ## Mean :1988 Mean : 55.31 Mean :64.81 Mean :4.084 Mean :2.701e+07 ## 3rd Qu.:2002 3rd Qu.: 85.10 3rd Qu.:73.00 3rd Qu.:6.000 3rd Qu.:1.523e+07 ## Max. :2016 Max. :276.90 Max. :83.90 Max. :9.220 Max. :1.376e+09 ## NA&#39;s :1453 NA&#39;s :187 NA&#39;s :185 ## gdp continent region ## Min. :4.040e+07 Length:10545 Length:10545 ## 1st Qu.:1.846e+09 Class :character Class :character ## Median :7.794e+09 Mode :character Mode :character ## Mean :1.480e+11 ## 3rd Qu.:5.540e+10 ## Max. :1.174e+13 ## NA&#39;s :2972 ## Warning in general_inspection(tables$gapminderDB): missing values for x, y 6.9 9. Load the gapminder data in R and change the dataframe in such as way that you could join it to dengue and flue. tables$fluDB$year %&gt;% unique() ## [1] 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 tables$dengueDB$year %&gt;% unique() ## [1] 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 The data of flu and dengue are from the year 2002 untill 2015. while the data of gapminder is from: tables$gapminderDB$year %&gt;% unique() ## [1] 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 2012 1976 1977 2014 1978 2016 1979 ## [24] 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 ## [47] 2003 2004 2005 2006 2007 2008 2009 2010 2011 2013 2015 1960 till 2015. weve also seen in 7.8 that the flu data has 406 rows while the dengue data has 140 rows. # db_names &lt;- c(&quot;tables$fluDB$country&quot;, &quot;tables$dengueDB$country&quot;, &quot;tables$gapminderDB$country&quot;) # for (i in db_names){ # amount_factor(get(i)) # } amount_factor(tables$fluDB$country) ## [1] &quot;tables$fluDB$country has 29 levels:&quot; ## [1] &quot;Argentina&quot; &quot;Australia&quot; &quot;Austria&quot; &quot;Belgium&quot; &quot;Bolivia&quot; &quot;Brazil&quot; &quot;Bulgaria&quot; ## [8] &quot;Canada&quot; &quot;Chile&quot; &quot;France&quot; &quot;Germany&quot; &quot;Hungary&quot; &quot;Japan&quot; &quot;Mexico&quot; ## [15] &quot;Netherlands&quot; &quot;New.Zealand&quot; &quot;Norway&quot; &quot;Paraguay&quot; &quot;Peru&quot; &quot;Poland&quot; &quot;Romania&quot; ## [22] &quot;Russia&quot; &quot;South.Africa&quot; &quot;Spain&quot; &quot;Sweden&quot; &quot;Switzerland&quot; &quot;Ukraine&quot; &quot;United.States&quot; ## [29] &quot;Uruguay&quot; amount_factor(tables$dengueDB$country) ## [1] &quot;tables$dengueDB$country has 10 levels:&quot; ## [1] &quot;Argentina&quot; &quot;Bolivia&quot; &quot;Brazil&quot; &quot;India&quot; &quot;Indonesia&quot; &quot;Mexico&quot; &quot;Philippines&quot; &quot;Singapore&quot; ## [9] &quot;Thailand&quot; &quot;Venezuela&quot; amount_factor(tables$gapminderDB$country) ## [1] &quot;tables$gapminderDB$country has 185 levels:&quot; ## [1] &quot;Albania&quot; &quot;Algeria&quot; &quot;Angola&quot; ## [4] &quot;Antigua and Barbuda&quot; &quot;Argentina&quot; &quot;Armenia&quot; ## [7] &quot;Aruba&quot; &quot;Australia&quot; &quot;Austria&quot; ## [10] &quot;Azerbaijan&quot; &quot;Bahamas&quot; &quot;Bahrain&quot; ## [13] &quot;Bangladesh&quot; &quot;Barbados&quot; &quot;Belarus&quot; ## [16] &quot;Belgium&quot; &quot;Belize&quot; &quot;Benin&quot; ## [19] &quot;Bhutan&quot; &quot;Bolivia&quot; &quot;Bosnia and Herzegovina&quot; ## [22] &quot;Botswana&quot; &quot;Brazil&quot; &quot;Brunei&quot; ## [25] &quot;Bulgaria&quot; &quot;Burkina Faso&quot; &quot;Burundi&quot; ## [28] &quot;Cambodia&quot; &quot;Cameroon&quot; &quot;Canada&quot; ## [31] &quot;Cape Verde&quot; &quot;Central African Republic&quot; &quot;Chad&quot; ## [34] &quot;Chile&quot; &quot;China&quot; &quot;Colombia&quot; ## [37] &quot;Comoros&quot; &quot;Congo, Dem. Rep.&quot; &quot;Congo, Rep.&quot; ## [40] &quot;Costa Rica&quot; &quot;Cote d&#39;Ivoire&quot; &quot;Croatia&quot; ## [43] &quot;Cuba&quot; &quot;Cyprus&quot; &quot;Czech Republic&quot; ## [46] &quot;Denmark&quot; &quot;Djibouti&quot; &quot;Dominican Republic&quot; ## [49] &quot;Ecuador&quot; &quot;Egypt&quot; &quot;El Salvador&quot; ## [52] &quot;Equatorial Guinea&quot; &quot;Eritrea&quot; &quot;Estonia&quot; ## [55] &quot;Ethiopia&quot; &quot;Fiji&quot; &quot;Finland&quot; ## [58] &quot;France&quot; &quot;French Polynesia&quot; &quot;Gabon&quot; ## [61] &quot;Gambia&quot; &quot;Georgia&quot; &quot;Germany&quot; ## [64] &quot;Ghana&quot; &quot;Greece&quot; &quot;Greenland&quot; ## [67] &quot;Grenada&quot; &quot;Guatemala&quot; &quot;Guinea&quot; ## [70] &quot;Guinea-Bissau&quot; &quot;Guyana&quot; &quot;Haiti&quot; ## [73] &quot;Honduras&quot; &quot;Hong Kong, China&quot; &quot;Hungary&quot; ## [76] &quot;Iceland&quot; &quot;India&quot; &quot;Indonesia&quot; ## [79] &quot;Iran&quot; &quot;Iraq&quot; &quot;Ireland&quot; ## [82] &quot;Israel&quot; &quot;Italy&quot; &quot;Jamaica&quot; ## [85] &quot;Japan&quot; &quot;Jordan&quot; &quot;Kazakhstan&quot; ## [88] &quot;Kenya&quot; &quot;Kiribati&quot; &quot;Kuwait&quot; ## [91] &quot;Kyrgyz Republic&quot; &quot;Lao&quot; &quot;Latvia&quot; ## [94] &quot;Lebanon&quot; &quot;Lesotho&quot; &quot;Liberia&quot; ## [97] &quot;Libya&quot; &quot;Lithuania&quot; &quot;Luxembourg&quot; ## [100] &quot;Macao, China&quot; &quot;Macedonia, FYR&quot; &quot;Madagascar&quot; ## [103] &quot;Malawi&quot; &quot;Malaysia&quot; &quot;Maldives&quot; ## [106] &quot;Mali&quot; &quot;Malta&quot; &quot;Mauritania&quot; ## [109] &quot;Mauritius&quot; &quot;Mexico&quot; &quot;Micronesia, Fed. Sts.&quot; ## [112] &quot;Moldova&quot; &quot;Mongolia&quot; &quot;Montenegro&quot; ## [115] &quot;Morocco&quot; &quot;Mozambique&quot; &quot;Namibia&quot; ## [118] &quot;Nepal&quot; &quot;Netherlands&quot; &quot;New Caledonia&quot; ## [121] &quot;New Zealand&quot; &quot;Nicaragua&quot; &quot;Niger&quot; ## [124] &quot;Nigeria&quot; &quot;Norway&quot; &quot;Oman&quot; ## [127] &quot;Pakistan&quot; &quot;Panama&quot; &quot;Papua New Guinea&quot; ## [130] &quot;Paraguay&quot; &quot;Peru&quot; &quot;Philippines&quot; ## [133] &quot;Poland&quot; &quot;Portugal&quot; &quot;Puerto Rico&quot; ## [136] &quot;Qatar&quot; &quot;Romania&quot; &quot;Russia&quot; ## [139] &quot;Rwanda&quot; &quot;Samoa&quot; &quot;Saudi Arabia&quot; ## [142] &quot;Senegal&quot; &quot;Serbia&quot; &quot;Seychelles&quot; ## [145] &quot;Sierra Leone&quot; &quot;Singapore&quot; &quot;Slovak Republic&quot; ## [148] &quot;Slovenia&quot; &quot;Solomon Islands&quot; &quot;South Africa&quot; ## [151] &quot;South Korea&quot; &quot;Spain&quot; &quot;Sri Lanka&quot; ## [154] &quot;St. Lucia&quot; &quot;St. Vincent and the Grenadines&quot; &quot;Sudan&quot; ## [157] &quot;Suriname&quot; &quot;Swaziland&quot; &quot;Sweden&quot; ## [160] &quot;Switzerland&quot; &quot;Syria&quot; &quot;Tajikistan&quot; ## [163] &quot;Tanzania&quot; &quot;Thailand&quot; &quot;Timor-Leste&quot; ## [166] &quot;Togo&quot; &quot;Tonga&quot; &quot;Trinidad and Tobago&quot; ## [169] &quot;Tunisia&quot; &quot;Turkey&quot; &quot;Turkmenistan&quot; ## [172] &quot;Uganda&quot; &quot;Ukraine&quot; &quot;United Arab Emirates&quot; ## [175] &quot;United Kingdom&quot; &quot;United States&quot; &quot;Uruguay&quot; ## [178] &quot;Uzbekistan&quot; &quot;Vanuatu&quot; &quot;Venezuela&quot; ## [181] &quot;Vietnam&quot; &quot;West Bank and Gaza&quot; &quot;Yemen&quot; ## [184] &quot;Zambia&quot; &quot;Zimbabwe&quot; levelF &lt;- tables$fluDB$country %&gt;% as.factor %&gt;% levels() levelD &lt;- tables$dengueDB$country %&gt;% as.factor %&gt;% levels() levelG &lt;- tables$gapminderDB$country %&gt;% as.factor %&gt;% levels() common(levelD, levelG) ## [1] &quot;Argentina&quot; &quot;Bolivia&quot; &quot;Brazil&quot; &quot;India&quot; &quot;Indonesia&quot; &quot;Mexico&quot; &quot;Philippines&quot; &quot;Singapore&quot; ## [9] &quot;Thailand&quot; &quot;Venezuela&quot; All the countries in the dengue data set are all also in the gapminder dataset. common(levelD, levelF) ## [1] &quot;Argentina&quot; &quot;Bolivia&quot; &quot;Brazil&quot; &quot;Mexico&quot; common(levelF, levelG) %&gt;% length() ## [1] &quot;Argentina&quot; &quot;Australia&quot; &quot;Austria&quot; &quot;Belgium&quot; &quot;Bolivia&quot; &quot;Brazil&quot; &quot;Bulgaria&quot; &quot;Canada&quot; ## [9] &quot;Chile&quot; &quot;France&quot; &quot;Germany&quot; &quot;Hungary&quot; &quot;Japan&quot; &quot;Mexico&quot; &quot;Netherlands&quot; &quot;Norway&quot; ## [17] &quot;Paraguay&quot; &quot;Peru&quot; &quot;Poland&quot; &quot;Romania&quot; &quot;Russia&quot; &quot;Spain&quot; &quot;Sweden&quot; &quot;Switzerland&quot; ## [25] &quot;Ukraine&quot; &quot;Uruguay&quot; ## [1] 26 but the flu data set only has in common with the dengue data set. If the tables are to be joined they need to have data about only the countries and years equal to the counties and years that the tables have in common. Or the tables need to be joined in a way that NA is introduced where necessary. gapminder_02_15 &lt;- tables$gapminderDB %&gt;% filter(between(year, 2002, 2015)) 6.10 10. Save this clean gapminder data in the workflowsdb database dbWriteTable(con, &quot;gapminder_02_15DB&quot;, gapminder_02_15, overwrite = T) 6.11 11. Perform some joins (your choice) with SQL (can be done in DBeaver or with dplyr). SELECT &quot;gapminder_02_15DB&quot;.*, &quot;fluDB&quot;.influenza_activity, &quot;dengueDB&quot;.dengue_activity FROM &quot;gapminder_02_15DB&quot; LEFT JOIN &quot;fluDB&quot; ON public.&quot;fluDB&quot;.year = public.&quot;gapminder_02_15DB&quot;.year AND public.&quot;fluDB&quot;.country = public.&quot;gapminder_02_15DB&quot;.country LEFT JOIN &quot;dengueDB&quot; ON public.&quot;dengueDB&quot;.year = public.&quot;gapminder_02_15DB&quot;.year AND public.&quot;dengueDB&quot;.country = public.&quot;gapminder_02_15DB&quot;.country Table 6.4: Displaying records 1 - 10 country year infant_mortality life_expectancy fertility population gdp continent region influenza_activity dengue_activity Argentina 2002 17.1 74.3 2.38 37889443 2.420762e+11 Americas South America 0 0.000 Australia 2002 5.0 80.3 1.76 19514385 4.421354e+11 Oceania Australia and New Zealand 0 NA Austria 2002 4.4 78.8 1.39 8114698 1.969986e+11 Europe Western Europe 0 NA Belgium 2002 4.4 78.2 1.68 10364613 2.377417e+11 Europe Western Europe 0 NA Bolivia 2002 53.7 68.7 3.98 8653343 8.751510e+09 Americas South America 0 0.101 Brazil 2002 24.3 71.4 2.26 181045592 6.705127e+11 Americas South America 174 0.073 Bulgaria 2002 16.3 72.1 1.22 7869124 1.406418e+10 Europe Eastern Europe 0 NA Canada 2002 5.3 79.6 1.51 31288572 7.594286e+11 Americas Northern America 0 NA Chile 2002 8.3 77.7 2.01 15544554 7.944855e+10 Americas South America 0 NA France 2002 4.2 79.4 1.87 60075783 1.363229e+12 Europe Western Europe 0 NA 6.12 12. Generate a joined table, and export this from the database to R. CREATE TABLE joined_gapfluden AS SELECT &quot;gapminder_02_15DB&quot;.*, &quot;fluDB&quot;.influenza_activity, &quot;dengueDB&quot;.dengue_activity FROM &quot;gapminder_02_15DB&quot; LEFT JOIN &quot;fluDB&quot; ON public.&quot;fluDB&quot;.year = public.&quot;gapminder_02_15DB&quot;.year AND public.&quot;fluDB&quot;.country = public.&quot;gapminder_02_15DB&quot;.country LEFT JOIN &quot;dengueDB&quot; ON public.&quot;dengueDB&quot;.year = public.&quot;gapminder_02_15DB&quot;.year AND public.&quot;dengueDB&quot;.country = public.&quot;gapminder_02_15DB&quot;.country joined_gapfluden &lt;- dbReadTable(conn = con, &quot;joined_gapfluden&quot;) dbDisconnect(con) 6.13 13. Show some descriptive statistics with this table, and at least 3 visualisations using ggplot2. First of all i there is no description what influenza activity actually is. I assume because its only positive integers that it means individuals infected. So i want to see if population has a correlation with influenza activity. joined_gapfluden %&gt;% filter(influenza_activity &gt; 0) %&gt;% ggplot(aes(x= influenza_activity, y=population))+ geom_point() + facet_wrap(~year) "]]
