[["portfolio-assignment-1-1.html", "Portfolio of DSFB 1 Portfolio assignment 1.1", " Portfolio of DSFB Lars de Groot 1 Portfolio assignment 1.1 A. Review the following Excel file in the ./data/CE.LIQ.FLOW.062_Tidydata.xlsx (its here), by opening the file in Excel. See if you can spot anything peculiar about this file. Do not edit the file in any way. Just close it when you are done. (Annoyingly, Excel asks you to save your changes, even if you did not touch anything in the file: why is this cumbersome?) Colourfull Excel file its bright with unreadable colors. The data is in wide/tidy format and many columns have the same value on each cell of the column. B. Open the file in R, using the {readxl} package. ce_data &lt;- read_xlsx(here(&quot;1.1_data/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;)) No the data types have not been correctly assigned, column compname could have been the data type factor, and compConcentration should be numeric. D. Create a graph displaying a scatterplot for the CE.LIQ.FLOW.062_Tidydata.xlsx data, for the different compounds and the varying concentrations. Put the compConcentration on the x-axis, the DataRaw counts on the y-axis and assign a colour to each level in compName. Assign a different symbol (shape =) to each level in the expType variable. Try fixing the labels of the x-axis so that we can read them. ce_data$compConcentration &lt;- as.numeric(ce_data$compConcentration) ## Warning: NAs introduced by coercion ce_data$compName &lt;- as_factor(ce_data$compName) ce_data %&gt;% slice_sample(prop = 0.40) %&gt;% ggplot(aes(x = compConcentration, y = RawData)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.3) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 1 rows containing missing values (geom_point). ce_data %&gt;% ggplot(aes(x = compConcentration, y = RawData)) + geom_point(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.3) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Ignoring unknown parameters: width ## Warning: Removed 6 rows containing missing values (geom_point). E. When creating the plot under C), what happened with the ordering of the x-axis labels. Explain why this happens. Look at the data-type of the compConcentration column in the data again to find a clue. ce_data &lt;- read_xlsx(here(&quot;1.1_data/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;)) ce_data %&gt;% ggplot(aes(x = compConcentration, y = RawData)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.2) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 5 rows containing missing values (geom_point). class(ce_data$compConcentration) ## [1] &quot;character&quot; The data type of compConcentration is character, this means per concentration value it adds a point on the x-axis. this results in the overplotted mess seen here. F. Correct the data-type of compConcentration to numeric and than look at the graph again. Use a log10 transformation on the x-axis to get a clear graph. Also, add a bit of jitter to the points in the graph so that points are not overlapping. ce_data$compConcentration &lt;- as.numeric(ce_data$compConcentration) ## Warning: NAs introduced by coercion ce_data %&gt;% ggplot(aes(x = log10(compConcentration), y = RawData)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.2) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 6 rows containing missing values (geom_point). G.H. Fill in: (G) The positive control for this experiments is ethanol (H) The negative control for this experiment isS-medium\" Think about how you would analyze this experiment to learn whether there is indeed an effect of different concentrations on offspring count and whether the different compounds have a different curve (IC50). Write down your analysis as a step-wise plan I would create dose-response curves based on the data per compound. I would calculate P-values to test if the diffrence between concentrations of a compound has a significant effect on the number of offspring. this would first be done by checking for normality (shapiro wilk and/or q-q plots) then doing a Anova or Friedmans. J. Normalize the data for the controlNegative in such a way that the mean value for controlNegative is exactly equal to 1 and that all other values are expressed as a fraction thereof. Rerun your graphs with the normalized data. #calculating mean of control negative outside of mutate because mutate doesn&#39;t like filter function CN_mean &lt;- ce_data %&gt;% filter(expType == &quot;controlNegative&quot;) %&gt;% select(&quot;RawData&quot;) %&gt;% colMeans() normalized_ce_data &lt;- ce_data %&gt;% mutate(norm_data = RawData/CN_mean) #checking if it&#39;s correct normalized_ce_data %&gt;% group_by(expType) %&gt;% summarise(m = mean(norm_data, na.rm = T)) ## # A tibble: 4 x 2 ## expType m ## &lt;chr&gt; &lt;dbl&gt; ## 1 controlNegative 1 ## 2 controlPositive 0.575 ## 3 controlVehicleA 1.07 ## 4 experiment 0.763 #making first plot normalized_ce_data %&gt;% slice_sample(prop = 0.40) %&gt;% ggplot(aes(x = compConcentration, y = norm_data)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.3) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 2 rows containing missing values (geom_point). #makng the log plot normalized_ce_data %&gt;% ggplot(aes(x = log10(compConcentration), y = norm_data)) + geom_jitter(aes(color = compName, shape = expType), alpha = 0.7, size = 1, width = 0.2) + labs(x = &quot;Compand concentration&quot;, y = &quot;Number of offspring,&quot;, title = &quot;Counted offspring after incubation with compound&quot;) ## Warning: Removed 6 rows containing missing values (geom_point). K. Why would you want to take the step under J? this eliminates natural and extraneous variation between groups. After normalization all groups fall on the same scale of 0 - 1. "],["portfolio-assignment-1-2-part-1.html", "2 Portfolio assignment 1.2 part 1 2.1 Score: 2.2 Explanation:", " 2 Portfolio assignment 1.2 part 1 This exercise is about identifying reproducibility issues in a scientific publication. We use the criteria for reproduciblity that are publically available via here. Article used: A retrospective cluster analysis of COVID-19 cases by county *** 2.1 Score: Transparency Criteria Definition Score Study Purpose A concise statement in the introduction of the article, often in the last paragraph, that establishes the reason the research was conducted. Also called the study objective. TRUE Data Availability Statement A statement, in an individual section offset from the main body of text, that explains how or if one can access a studys data. The title of the section may vary, but it must explicitly mention data; it is therefore distinct from a supplementary materials section. TRUE Data Location Where the articles data can be accessed, either raw or processed. TRUE Study Location Author has stated in the methods section where the study took place or the datas country/region of origin. TRUE Author Review The professionalism of the contact information that the author has provided in the manuscript. TRUE Ethics Statement A statement within the manuscript indicating any ethical concerns, including the presence of sensitive data. FALSE Funding Statement A statement within the manuscript indicating whether or not the authors received funding for their research. FALSE Code Availability Authors have shared access to the most updated code that they used in their study, including code used for analysis. TRUE 2.2 Explanation: At the top of the article the authors names are displayed, with the names of the universities the study at or are part of. Of one of the authors the email is given. This information falls under the author review criteria. this information is sufficient for the goal of open science in this case because email, department and phone number information can be found online for these scientist. however this might not always be the case so the availability of the email address of the paper is appreciated. The article aims to better understand the pattern of outbreaks of COVID-19 within the US. it states this as a study purpose at the end of the introduction paragraph. it then continuous to formulate 3 research questions which further clarifies the study purpose: How many distinct clusters of counties exhibit similar COVID-19 patterns in the time-series of daily confirmed cases? What is the geographic distribution of the counties within each cluster? Are county-level demographic, socioeconomic and political variables associated with the COVID-19 case patterns? the article then starts to give a detailed description of the methods used in the study, it does this in stages. In the paragraph Stage 0: Data Acquisition and Preprocessing, it starts with explaining what the sources are for the data used in the study. this is a example of the criteria data location. However no link was supplied. At further inspection the data used here came from the R package 'COVID-19', And in the references it does specify the date of accessing the data hub. Also the locations of supplementary data that wasnt taken from other sources is listed in the same paragraph. However not all of the links provided work anymore. working_links &lt;- tibble(&quot;Data used&quot; = c(&quot;Rural and Underserved Counties List&quot;, &quot;Population Density&quot;, &quot;Voting Results&quot;, &quot;Governors Party Affiliation&quot;, &quot;Health Variables&quot;, &quot;Region&quot;), &quot;Link Provided&quot; = c(&quot;https://www.consumerfinance.gov/documents/8911/cfpbrural-underserved-list2020.csv&quot;, &quot;https://www2.census.gov/library/publications/2011/compendia/usacounties/excel/LND01.xls&quot;,&quot;https://doi.org/10.7910/DVN/VOQCHQ&quot;,&quot;https://en.wikipedia.org/w/index.php?title=ListofUnitedStatesgovernors&amp;oldid=977828843&quot;,&quot;https://khn.org/news/as-coronavirus-spreadswidely-millionsof-older-americans-live-in-counties-with-no-icu-beds/#lookup&quot;,&quot;https://www.cdc.gov/coordinatedchronic/docs/nccdphp-regions-map.pdf&quot;), &quot;Link working?&quot; = c(F, F, T, T, F, F) ) knitr::kable(working_links) Data used Link Provided Link working? Rural and Underserved Counties List https://www.consumerfinance.gov/documents/8911/cfpbrural-underserved-list2020.csv FALSE Population Density https://www2.census.gov/library/publications/2011/compendia/usacounties/excel/LND01.xls FALSE Voting Results https://doi.org/10.7910/DVN/VOQCHQ TRUE Governors Party Affiliation https://en.wikipedia.org/w/index.php?title=ListofUnitedStatesgovernors&amp;oldid=977828843 TRUE Health Variables https://khn.org/news/as-coronavirus-spreadswidely-millionsof-older-americans-live-in-counties-with-no-icu-beds/#lookup FALSE Region https://www.cdc.gov/coordinatedchronic/docs/nccdphp-regions-map.pdf FALSE This shows how simply providing links to data used isnt enough because the validity of the repository which host the data isnt always guaranteed. but later in the article under Supporting information it also links to a github page. This is a great example of open science because the data location where the data originates from is stated, and a neat collection of data used within the study is given. within this same paragraph it is stated: To capture the progression of disease in the U.S., the number of confirmed COVID-19 cases at the county level from March 1, 2020 through October 24, 2020 was extracted from the COVID-19 data hub [4]. Only data from the contiguous 48 states were included. In this sentence the region of origin of the data is described, thus the criteria Study location has been met. Under acknowledgements is where you would expect there to a funding statement. But it simple states none. hereby it is neither denied or confirmed that this study is funded so this article does not meet the criteria Funding statement. After the references there is supporting information paragraph, which states what program was used (R), the version (4.0.2), and gives a link to a github page, which sadly no longer works. But the user page can be derivated from the link and so the data used (raw and processed) can be accesed. which is why the article meets the criteria Data Availability Statement and Code Availability. Futher more no ethical concerns were raised in the article so it doesnt meet the criteria Ethics Statement. However this considering the way the study was conducted, there was no need for a ethics statement. "],["portfolio-assignment-1-2-part-2.html", "3 Portfolio assignment 1.2 part 2", " 3 Portfolio assignment 1.2 part 2 H. Using the OSF website, select a project that addresses an aspect of the SARS-Cov-2 virus. I. Select a project that has a dataset and R-code shared in the project environment. Project selected: Bats and COVID-19 J. Have a look at the code. Describe in your own words what the code intents to achieve. it downloads gtrends data for the quary bats and the word bat translated in diffrent langueses in there associated geolocations, for the time period 2016 to 2020. using this it makes figures that outline the correlation between searches about covid-19 and searches about bats. K. In terms of readibility of the code, how would you grade (1(very bad)-5(very good)) the code available. i would give it a 4, the code includes comments outlining the function of big code chunks, however the code uses packages and function im not familiar with so it still quite hard to really understand what the code does. L. Download the code and the data to a new RStudio project M. Run the script or code that is available to reproduce at least 1 figure tv.dat &lt;- read.csv(file=&quot;~/Documents/Research_Projects/Ongoing/BatsCovid/NewAnalysis_Dec2020/Data/Weekly/USTelevision/GDELTBatsUS1620.csv&quot;) tv.dat$date &lt;- ymd(tv.dat$date) tv.dat[61, &quot;date&quot;] &lt;- &quot;2021-01-01&quot; tv.dat[61, &quot;value&quot;] &lt;- NA tv.dat[61, &quot;X&quot;] &lt;- 61 ggplot() + geom_line(data=tv.dat, aes(x=X, y=value), size=0.8, color=&quot;steelblue&quot;, linetype=&quot;solid&quot;) + theme_bw() + scale_x_continuous(breaks=c(1, 13, 25, 37, 49, 61), labels=c(&quot;2016&quot;, &quot;2017&quot;, &quot;2018&quot;, &quot;2019&quot;, &quot;2020&quot;, &quot;2021&quot;)) + theme(axis.text.x = element_text(colour=&quot;black&quot;,size=14,angle=0,hjust=.5,vjust=.5,face=&quot;plain&quot;), axis.text.y = element_text(colour=&quot;black&quot;,size=14,angle=0,hjust=1,vjust=0,face=&quot;plain&quot;), axis.title.x = element_text(colour=&quot;black&quot;,size=12,angle=0,hjust=.5,vjust=.5,face=&quot;plain&quot;), axis.title.y = element_text(colour=&quot;black&quot;,size=12,angle=90,hjust=.5,vjust=.5,face=&quot;plain&quot;), plot.title = element_text(size=22, face=&quot;bold&quot;)) + theme(strip.background =element_rect(fill=&quot;wheat&quot;)) + labs(x=&quot;&quot;, y=&quot;&quot;) + theme(strip.text = element_text(colour = &quot;black&quot;, size=14, face=&quot;bold&quot;)) N. When you encounter errors or flaws in the script, try fixing them and record your changes. Errors: Error in file(file, rt) : cannot open the connection changed the filepath so it matches mine. Error in ymd(tv.dat$date) : could not find function ymd. ymd is part of the lubridate package, loaded the lubridate package. library(lubridate) tv.dat &lt;- read.csv(file=(here(&quot;1.2_data/GDELTBatsUS1620.csv&quot;))) tv.dat$date &lt;- ymd(tv.dat$date) tv.dat[61, &quot;date&quot;] &lt;- &quot;2021-01-01&quot; tv.dat[61, &quot;value&quot;] &lt;- NA tv.dat[61, &quot;X&quot;] &lt;- 61 ggplot() + geom_line(data=tv.dat, aes(x=X, y=value), size=0.8, color=&quot;steelblue&quot;, linetype=&quot;solid&quot;) + theme_bw() + scale_x_continuous(breaks=c(1, 13, 25, 37, 49, 61), labels=c(&quot;2016&quot;, &quot;2017&quot;, &quot;2018&quot;, &quot;2019&quot;, &quot;2020&quot;, &quot;2021&quot;)) + theme(axis.text.x = element_text(colour=&quot;black&quot;,size=14,angle=0,hjust=.5,vjust=.5,face=&quot;plain&quot;), axis.text.y = element_text(colour=&quot;black&quot;,size=14,angle=0,hjust=1,vjust=0,face=&quot;plain&quot;), axis.title.x = element_text(colour=&quot;black&quot;,size=12,angle=0,hjust=.5,vjust=.5,face=&quot;plain&quot;), axis.title.y = element_text(colour=&quot;black&quot;,size=12,angle=90,hjust=.5,vjust=.5,face=&quot;plain&quot;), plot.title = element_text(size=22, face=&quot;bold&quot;)) + theme(strip.background =element_rect(fill=&quot;wheat&quot;)) + labs(x=&quot;&quot;, y=&quot;&quot;) + theme(strip.text = element_text(colour = &quot;black&quot;, size=14, face=&quot;bold&quot;)) ## Warning: Removed 1 row(s) containing missing values (geom_path). O. Taken together on a scale from 1 (very hard) to 5 (very easy), how much effort did it take you to reproduce the visualization from the project, report or article. 5 very easy, the code used uses common packages and is very readable. P. Generate an RMarkdown script that contains the details on the project you selected, the code you used to create the visualization and your score for reproducibility. "],["portfolio-assignment-2.html", "4 Portfolio assignment 2", " 4 Portfolio assignment 2 Applying the Guerrilla analytics framework to your own project. Look at your RStudio project that you created for the DAUR-II final assignment Rearrange your project according the Guerilla principles explained above Add README files to the datasets Use the {fs} package to share a screenshot of your folder tree in your portfolio, look at: for more info on how to use the {fs} package. B. Now clean up your work environment for this course (workflows) and the parallel course in DSFB2 (projecticum). Set up a folder structure that will accomodate future plans and collaboration on the projecticum. Provide readme-files or comments within the code where needed. dir_tree(&quot;/Users/larsd/Documents/R/DSFB/DAUR2_eindopdracht&quot;, recurse = TRUE) ## /Users/larsd/Documents/R/DSFB/DAUR2_eindopdracht ## +-- DAUR2_eindopdracht.Rproj ## +-- DAUR2_eindopdracht_v1.Rmd ## +-- DAUR2_eindopdracht_v2.Rmd ## +-- DAUR2_eindopdracht_v3.Rmd ## +-- DAUR2_eindopdracht_v4.Rmd ## +-- DAUR2_eindopdracht_v5.Rmd ## +-- DAUR2_eindopdracht_v6.Rmd ## +-- DAUR2_eindopdracht_v7.Rmd ## +-- images ## | \\-- seqalignmentv6.jpeg ## +-- index.Rmd ## +-- rsconnect ## | \\-- documents ## | \\-- index.Rmd ## | \\-- bookdown.org ## | \\-- larsdgsp ## | \\-- DAUR2_eindopdracht.dcf ## +-- supplementory ## | \\-- vragen_eindopdracht_Daniel_Lars[2430].docx ## +-- _book ## | +-- images ## | | \\-- seqalignmentv6.jpeg ## | +-- libs ## | | +-- anchor-sections-1.0.1 ## | | | +-- anchor-sections.css ## | | | \\-- anchor-sections.js ## | | +-- gitbook-2.6.7 ## | | | +-- css ## | | | | +-- fontawesome ## | | | | | \\-- fontawesome-webfont.ttf ## | | | | +-- plugin-bookdown.css ## | | | | +-- plugin-clipboard.css ## | | | | +-- plugin-fontsettings.css ## | | | | +-- plugin-highlight.css ## | | | | +-- plugin-search.css ## | | | | +-- plugin-table.css ## | | | | \\-- style.css ## | | | \\-- js ## | | | +-- app.min.js ## | | | +-- clipboard.min.js ## | | | +-- jquery.highlight.js ## | | | +-- lunr.js ## | | | +-- plugin-bookdown.js ## | | | +-- plugin-clipboard.js ## | | | +-- plugin-fontsettings.js ## | | | +-- plugin-search.js ## | | | \\-- plugin-sharing.js ## | | +-- header-attrs-2.8 ## | | | \\-- header-attrs.js ## | | +-- jquery-2.2.3 ## | | | \\-- jquery.min.js ## | | +-- kePrint-0.0.1 ## | | | \\-- kePrint.js ## | | \\-- lightable-0.0.1 ## | | \\-- lightable.css ## | +-- reference-keys.txt ## | +-- search_index.json ## | +-- section.html ## | +-- vraag-1-finding-nemo.html ## | +-- vraag-2-lion-king.html ## | +-- vraag3-diabetes.html ## | +-- vraag4-sars-cov-19-virus.html ## | +-- vraag5-cpg-islands.html ## | +-- vraag6-hox-genes.html ## | +-- vraag7-airway.html ## | \\-- _main_files ## | \\-- figure-html ## | +-- berekening-1.png ## | +-- onderzoeksvraag 2-1.png ## | +-- onderzoeksvraag 2-2.png ## | +-- unnamed-chunk-10-1.png ## | +-- unnamed-chunk-12-1.png ## | +-- unnamed-chunk-13-1.png ## | +-- vraag 5_d-1.png ## | \\-- vraag 5_e2-1.png ## \\-- _bookdown_files ## +-- _main_cache ## | \\-- html ## | +-- data install_4c48a4715893e487cd83eea600fd62a5.RData ## | +-- data install_4c48a4715893e487cd83eea600fd62a5.rdb ## | +-- data install_4c48a4715893e487cd83eea600fd62a5.rdx ## | +-- vraag 1_c471dc67424cb02aa57f382a46ab702d.RData ## | +-- vraag 1_c471dc67424cb02aa57f382a46ab702d.rdb ## | +-- vraag 1_c471dc67424cb02aa57f382a46ab702d.rdx ## | \\-- __packages ## \\-- _main_files ## \\-- figure-html ## +-- berekening-1.png ## +-- onderzoeksvraag 2-1.png ## +-- onderzoeksvraag 2-2.png ## +-- unnamed-chunk-10-1.png ## +-- unnamed-chunk-12-1.png ## +-- unnamed-chunk-13-1.png ## +-- unnamed-chunk-9-1.png ## +-- vraag 5_d-1.png ## \\-- vraag 5_e2-1.png "],["rmarkdown-cv.html", "5 Rmarkdown CV", " 5 Rmarkdown CV My RMD CV can be found here "],["portfolio-assignment-5-b.html", "6 Portfolio assignment 5.B", " 6 Portfolio assignment 5.B 1. Make a new folder within Mendeley for the projecticum. Place all pdfs you used till now in your folder (if you did not use any papers as source yet, find 3 papers on Pubmed now that you could use for your introduction.). Copy your .bib file to the folder on your computer you are using for the Projecticum git repo. Our projecticum doesnt require a literature study Ive searched for papers about de novo assembly, and consensus algorithms for an internship talk. 2. Start a .Rmd named introduction.Rmd with a few lines introduction on your projecticum topic. 3. Include automatic inline references to the papers you used. 4. The bibliography will be placed at the end of the document. Provide an appropriate header. 5. Merge your work with that of your projecticum partner through github. Solve all the problems you encounter. If github does not want to merge .bib files and you want a merged one, try here. 6. Find out how you can add websites as reference to Mendeley. using the chrome extension found here 7. Write (so not copy!) at least 500 words of introduction for your projecticum project and use at least 5 references. this wont be an introduction but more of a summary Ive wrote a summary about some of the information ive found here Portfolio assignment 6.2 "],["portfolio-assignment-6-2.html", "7 Portfolio assignment 6.2", " 7 Portfolio assignment 6.2 In two years time id like to be doing a masters in bioinformatics. ive found that i enjoy the act of writing code and coming up with systems, and a higher degree in bioinformatics would allow me to land a job that would include this kind of work. Also my interest in research lies with how i view the potential of technology. I tend to see the potential of innovative research, what it could lead too. and this motivates me to want to work on projects that could lead to exciting advances. One branch of technology that has captured my interest in such a way is the possibilities of fast and cheap sequencing. after a masters in bioinformatics id like to work on projects that aim to improve sequencing accuracy. This goal requires me to research de novo assembly, consensus algorithms and the current state of sequencing technology. As an exercise ill summarize the information i have found regarding these subjects. The current state of NGS lies mostly with three separate systems for sequencing: Illumina with its HiSeq system, Ion torrent with its pyrosequencing and a third generation sequencer the oxford nanopore. These three all rely on different chemistry and methods to decode a DNA strand. The principal of a illumina sequencer is that the DNA library with adapters gets grafted to a flow cell. These single strands of DNA get amplified by bridge amplification. this creates clusters of clonal DNA strands. then the actual sequencing step begins by synthesizing the antiparalel strand, with nucleotides that contain cleavable fluorescent dyes. A nucleotide gets implemented, the flowcell gets scanned for fluorescence, the fluorescense dye gets cleaved. this step repeats until the entire strand of dna is sequenced. A ion torrent sequencer relies on the detection of pyrophosphate released during the incorporation of a nucleotide. DNA strands are captured by beads and amplified with emulsion PCR. Now beads with multiple clonal strands of DNA will be washed over a well plate, a single well can only hold a single bead. a solution of one of the nucleotides get washed over this well plate. A nucleotide gets implemented and pyrophosphate gets released equal to the amount of nucleotides implemented. pyrophosphate gets detected via a luciferase reaction, which generates light. the Nanopore sequencer get its name from the tiny biopores it used to detect the sequence of a DNA strand. These pores are embedded on a lipid bilayer which facilitates ion exchange. A nucleotide moving through the pore causes a disruption of the voltage over this pore, which is detected. By moving a a single stranded DNA strand through the pore current modulation is recorded. this current modulation is then used to determine the sequence of the DNA strand. [@generic] After data is collected there still is the problem of creating an actual genome/sequence out of it. Creating a whole genome out of just sequencing data without a reference genome is called whole genome de novo sequencing assembly. The basic process is: overlapping reads to form contigs, large stretches of consensus sequences without gaps. Then a scaffolding phase in which the order of the contigs is determined by large-insert reads.[@web_page] And a final gap filling stage where gaps between contigs can be filled using remaining short reads. however a de novo assembly is different based on which sequencing technology is used. For Illumina with its short reads a de Bruijn graph is most commonly used. de bruijn graph A de bruijn graph simplifies the contig creation step for a computer. Instead of having to keep the data of each read sequence in memory, and with what reads it overlaps, It divides reads up in K-mers. It hold a single K-mer of each unique K-mer in memory. To remember the sequence a path between K-mers is made, if a k-mer repeats the path loops back. To determine overlap a score can be made based on the amount of overlapping k-mers. This improves one of the big challenges of de novo assembly; the great amount of computational power and time required to make such a assembly. However de novo assembly using short reads comes with a problem. Genomes contain long repeating sequences that cant be bridged by short reads. Tactics to solve this is using large insert reads or using single molecule sequencer reads, such as the reads from the nanopore sequencer. Large insert reads are short reads that are the tips of a larger fragment. By using a technique in the lap these fragments are of a certain determined size. And by ligating special adapters to them they can later be identified. So during assembly when these reads show overlap between two contigs the distance between these contigs can be estimated. This technique creates a more complicated de bruijn graph however. Using a hybrid approach of short illumina read and long nanopore reads tend to create a simpler graph, and thus shortens computational time. [@article] A assembly using only long reads is also possible, and seems to be where the future of the technology lies. Assembly using only long reads goes to the same steps of contig creation and scaffolding. However since reads are so long contigs can be the size on an entire chromosome so scaffolding wont be needed. "],["portfolio-assignment-7.html", "8 Portfolio assignment 7", " 8 Portfolio assignment 7 source(here(&quot;src/port_src7.R&quot;)) 1. Load the flu (./data/flu_data.csv), the dengue (./data/dengue_data.csv) and the gapminder ({dslabs} package) into three separate dataframes in R. dengue &lt;- read.csv(here::here(&quot;7_data/dengue_data.txt&quot;), skip = 11) head(dengue) ## Date Argentina Bolivia Brazil India Indonesia Mexico Philippines Singapore Thailand Venezuela ## 1 2002-12-29 NA 0.101 0.073 0.062 0.101 NA NA 0.059 NA NA ## 2 2003-01-05 NA 0.143 0.098 0.047 0.039 NA NA 0.059 NA NA ## 3 2003-01-12 NA 0.176 0.119 0.051 0.059 0.071 NA 0.238 NA NA ## 4 2003-01-19 NA 0.173 0.170 0.032 0.039 0.052 NA 0.175 NA NA ## 5 2003-01-26 NA 0.146 0.138 0.040 0.112 0.048 NA 0.164 NA NA ## 6 2003-02-02 NA 0.160 0.202 0.038 0.049 0.041 NA 0.163 NA NA flu &lt;- read.csv(here::here(&quot;7_data/flu_data.txt&quot;), skip = 11) head(flu) ## Date Argentina Australia Austria Belgium Bolivia Brazil Bulgaria Canada Chile France Germany Hungary Japan Mexico ## 1 2002-12-29 NA NA NA NA NA 174 NA NA NA NA NA NA NA NA ## 2 2003-01-05 NA NA NA NA NA 162 NA NA NA NA NA NA NA NA ## 3 2003-01-12 NA NA NA NA NA 174 NA NA 1 NA NA NA NA NA ## 4 2003-01-19 NA NA NA NA NA 162 NA NA 0 NA NA NA NA NA ## 5 2003-01-26 NA NA NA NA NA 131 NA NA 0 NA NA NA NA NA ## 6 2003-02-02 136 NA NA NA NA 151 NA NA 0 NA NA NA NA NA ## Netherlands New.Zealand Norway Paraguay Peru Poland Romania Russia South.Africa Spain Sweden Switzerland Ukraine ## 1 NA NA NA NA 329 NA NA NA NA NA NA NA NA ## 2 NA NA NA NA 315 NA NA NA NA NA NA NA NA ## 3 NA NA NA NA 314 NA NA NA NA NA NA NA NA ## 4 NA NA NA NA 267 NA NA NA NA NA NA NA NA ## 5 NA NA NA NA 241 NA NA NA NA NA NA NA NA ## 6 NA NA NA NA 227 NA NA NA NA NA NA NA NA ## United.States Uruguay ## 1 NA NA ## 2 NA NA ## 3 NA NA ## 4 NA NA ## 5 NA NA ## 6 NA NA head(gapminder) ## country year infant_mortality life_expectancy fertility population gdp continent region ## 1 Albania 1960 115.40 62.87 6.19 1636054 NA Europe Southern Europe ## 2 Algeria 1960 148.20 47.50 7.65 11124892 13828152297 Africa Northern Africa ## 3 Angola 1960 208.00 35.98 7.32 5270844 NA Africa Middle Africa ## 4 Antigua and Barbuda 1960 NA 62.97 4.43 54681 NA Americas Caribbean ## 5 Argentina 1960 59.87 65.39 3.11 20619075 108322326649 Americas South America ## 6 Armenia 1960 NA 66.86 4.55 1867396 NA Asia Western Asia 2. Check if they are in the right shape. Is the data in the tidy format? If not change the format to tidy dengue &lt;- dengue %&gt;% pivot_longer(Argentina:Venezuela, names_to = &quot;country&quot;, values_to = &quot;value&quot;) head(dengue) ## # A tibble: 6 x 3 ## Date country value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2002-12-29 Argentina NA ## 2 2002-12-29 Bolivia 0.101 ## 3 2002-12-29 Brazil 0.073 ## 4 2002-12-29 India 0.062 ## 5 2002-12-29 Indonesia 0.101 ## 6 2002-12-29 Mexico NA flu &lt;- flu %&gt;% pivot_longer(Argentina:Uruguay, names_to = &quot;country&quot;, values_to = &quot;value&quot;) head(flu) ## # A tibble: 6 x 3 ## Date country value ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 2002-12-29 Argentina NA ## 2 2002-12-29 Australia NA ## 3 2002-12-29 Austria NA ## 4 2002-12-29 Belgium NA ## 5 2002-12-29 Bolivia NA ## 6 2002-12-29 Brazil 174 3. Change the country and date variables of the three tables so that they coincide in terms of data type, class and values dengue &lt;- dengue %&gt;% separate(&quot;Date&quot;, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep = &quot;-&quot;) dengue &lt;- dengue[-c(2,3)] dengue$year &lt;- as.integer(dengue$year) dengue$country &lt;- as.factor(dengue$country) dengue &lt;- dengue %&gt;% group_by(year, country) %&gt;% summarise(&quot;country&quot; = country, &quot;dengue_activity&quot; = sum(value, na.rm = T)) %&gt;% unique() ## `summarise()` has grouped output by &#39;year&#39;, &#39;country&#39;. You can override using the `.groups` argument. head(dengue) ## # A tibble: 6 x 3 ## # Groups: year, country [6] ## year country dengue_activity ## &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 2002 Argentina 0 ## 2 2002 Bolivia 0.101 ## 3 2002 Brazil 0.073 ## 4 2002 India 0.062 ## 5 2002 Indonesia 0.101 ## 6 2002 Mexico 0 flu &lt;- flu %&gt;% separate(&quot;Date&quot;, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep = &quot;-&quot;) flu &lt;- flu[-c(2,3)] flu$year &lt;- as.integer(flu$year) flu$country &lt;- as.factor(flu$country) flu &lt;- flu %&gt;% group_by(year, country) %&gt;% summarise(&quot;country&quot; = country, &quot;influenza_activity&quot; = sum(value, na.rm = T)) %&gt;% unique() ## `summarise()` has grouped output by &#39;year&#39;, &#39;country&#39;. You can override using the `.groups` argument. head(flu) ## # A tibble: 6 x 3 ## # Groups: year, country [6] ## year country influenza_activity ## &lt;int&gt; &lt;fct&gt; &lt;int&gt; ## 1 2002 Argentina 0 ## 2 2002 Australia 0 ## 3 2002 Austria 0 ## 4 2002 Belgium 0 ## 5 2002 Bolivia 0 ## 6 2002 Brazil 174 4. Store the three tables as separate (so six in total) .csv and .rds files. for (x in c(&quot;flu&quot;, &quot;dengue&quot;, &quot;gapminder&quot;)) { export(get(x), path = paste0(here(&quot;7_data//&quot;), x)) } 5. In Dbeaver create a new PostgreSQL database workflowsdb knitr::include_graphics(here(&quot;7_data/workflowsdb_in_Dbeaver.JPG&quot;)) Figure 8.1: The workflows database in Dbeaver. Workflows database in DBeaver 6. Using RPostgreSQL, insert the tables into the database. psswd &lt;- .rs.askForPassword(&quot;Database Password:&quot;) con &lt;- dbConnect(RPostgres::Postgres(), dbname = &quot;workflowsdb&quot;, host=&quot;localhost&quot;, port=&quot;5432&quot;, user=&quot;postgres&quot;, password=psswd) dbWriteTable(con, &quot;dengueDB&quot;, dengue, overwrite = T) dbWriteTable(con, &quot;fluDB&quot;, flu, overwrite = T) dbWriteTable(con, &quot;gapminderDB&quot;, gapminder, overwrite = T) 7. Inspect the contents of the tables with SQL (in DBeaver) and save the SQL script. SELECT * FROM &quot;dengueDB&quot;; Table 8.1: Displaying records 1 - 10 year country dengue_activity 2002 Argentina 0.000 2002 Bolivia 0.101 2002 Brazil 0.073 2002 India 0.062 2002 Indonesia 0.101 2002 Mexico 0.000 2002 Philippines 0.000 2002 Singapore 0.059 2002 Thailand 0.000 2002 Venezuela 0.000 SELECT * FROM &quot;fluDB&quot;; Table 8.2: Displaying records 1 - 10 year country influenza_activity 2002 Argentina 0 2002 Australia 0 2002 Austria 0 2002 Belgium 0 2002 Bolivia 0 2002 Brazil 174 2002 Bulgaria 0 2002 Canada 0 2002 Chile 0 2002 France 0 SELECT * FROM &quot;gapminderDB&quot;; Table 8.3: Displaying records 1 - 10 country year infant_mortality life_expectancy fertility population gdp continent region Albania 1960 115.40 62.87 6.19 1636054 NA Europe Southern Europe Algeria 1960 148.20 47.50 7.65 11124892 13828152297 Africa Northern Africa Angola 1960 208.00 35.98 7.32 5270844 NA Africa Middle Africa Antigua and Barbuda 1960 NA 62.97 4.43 54681 NA Americas Caribbean Argentina 1960 59.87 65.39 3.11 20619075 108322326649 Americas South America Armenia 1960 NA 66.86 4.55 1867396 NA Asia Western Asia Aruba 1960 NA 65.66 4.82 54208 NA Americas Caribbean Australia 1960 20.30 70.87 3.45 10292328 96677859364 Oceania Australia and New Zealand Austria 1960 37.30 68.75 2.70 7065525 52392699681 Europe Western Europe Azerbaijan 1960 NA 61.33 5.57 3897889 NA Asia Western Asia 8. Inspect the contents of the tables with dplyr (in R) and save a RMarkdown showing what you are doing. db_names &lt;- c(&quot;fluDB&quot;, &quot;dengueDB&quot;, &quot;gapminderDB&quot;) tables &lt;- list() for (i in db_names){ tables[[paste(i)]] &lt;- dbReadTable(con, i) } general_inspection(tables$fluDB, tables$fluDB$year, tables$fluDB$influenza_activity) ## [1] &quot;The data frame tables$fluDB has 3 columns: year, country, influenza_activity&quot; ## [1] &quot;And 406 rows&quot; ## year country influenza_activity ## Min. :2002 Length:406 Min. : 0 ## 1st Qu.:2005 Class :character 1st Qu.: 1696 ## Median :2008 Mode :character Median : 6772 ## Mean :2008 Mean : 20147 ## 3rd Qu.:2012 3rd Qu.: 24975 ## Max. :2015 Max. :155577 general_inspection(tables$dengueDB, tables$dengueDB$year, tables$dengueDB$dengue_activity) ## [1] &quot;The data frame tables$dengueDB has 3 columns: year, country, dengue_activity&quot; ## [1] &quot;And 140 rows&quot; ## year country dengue_activity ## Min. :2002 Length:140 Min. : 0.000 ## 1st Qu.:2005 Class :character 1st Qu.: 2.346 ## Median :2008 Mode :character Median : 5.556 ## Mean :2008 Mean : 6.217 ## 3rd Qu.:2012 3rd Qu.: 8.824 ## Max. :2015 Max. :27.847 general_inspection(tables$gapminderDB) ## [1] &quot;The data frame tables$gapminderDB has 9 columns: country, year, infant_mortality, life_expectancy, fertility, population, gdp, continent, region&quot; ## [1] &quot;And 10545 rows&quot; ## country year infant_mortality life_expectancy fertility population gdp ## Length:10545 Min. :1960 Min. : 1.50 Min. :13.20 Min. :0.840 Min. :3.124e+04 Min. :4.040e+07 ## Class :character 1st Qu.:1974 1st Qu.: 16.00 1st Qu.:57.50 1st Qu.:2.200 1st Qu.:1.333e+06 1st Qu.:1.846e+09 ## Mode :character Median :1988 Median : 41.50 Median :67.54 Median :3.750 Median :5.009e+06 Median :7.794e+09 ## Mean :1988 Mean : 55.31 Mean :64.81 Mean :4.084 Mean :2.701e+07 Mean :1.480e+11 ## 3rd Qu.:2002 3rd Qu.: 85.10 3rd Qu.:73.00 3rd Qu.:6.000 3rd Qu.:1.523e+07 3rd Qu.:5.540e+10 ## Max. :2016 Max. :276.90 Max. :83.90 Max. :9.220 Max. :1.376e+09 Max. :1.174e+13 ## NA&#39;s :1453 NA&#39;s :187 NA&#39;s :185 NA&#39;s :2972 ## continent region ## Length:10545 Length:10545 ## Class :character Class :character ## Mode :character Mode :character ## ## ## ## ## Warning in general_inspection(tables$gapminderDB): missing values for x, y 9. Load the gapminder data in R and change the dataframe in such as way that you could join it to dengue and flue. tables$fluDB$year %&gt;% unique() ## [1] 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 tables$dengueDB$year %&gt;% unique() ## [1] 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 The data of flu and dengue are from the year 2002 untill 2015. while the data of gapminder is from: tables$gapminderDB$year %&gt;% unique() ## [1] 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 2012 1976 1977 2014 1978 2016 1979 1980 ## [25] 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 ## [49] 2005 2006 2007 2008 2009 2010 2011 2013 2015 1960 till 2015. weve also seen in 7.8 that the flu data has 406 rows while the dengue data has 140 rows. # db_names &lt;- c(&quot;tables$fluDB$country&quot;, &quot;tables$dengueDB$country&quot;, &quot;tables$gapminderDB$country&quot;) # for (i in db_names){ # amount_factor(get(i)) # } amount_factor(tables$fluDB$country) ## [1] &quot;tables$fluDB$country has 29 levels:&quot; ## [1] &quot;Argentina&quot; &quot;Australia&quot; &quot;Austria&quot; &quot;Belgium&quot; &quot;Bolivia&quot; &quot;Brazil&quot; &quot;Bulgaria&quot; ## [8] &quot;Canada&quot; &quot;Chile&quot; &quot;France&quot; &quot;Germany&quot; &quot;Hungary&quot; &quot;Japan&quot; &quot;Mexico&quot; ## [15] &quot;Netherlands&quot; &quot;New.Zealand&quot; &quot;Norway&quot; &quot;Paraguay&quot; &quot;Peru&quot; &quot;Poland&quot; &quot;Romania&quot; ## [22] &quot;Russia&quot; &quot;South.Africa&quot; &quot;Spain&quot; &quot;Sweden&quot; &quot;Switzerland&quot; &quot;Ukraine&quot; &quot;United.States&quot; ## [29] &quot;Uruguay&quot; amount_factor(tables$dengueDB$country) ## [1] &quot;tables$dengueDB$country has 10 levels:&quot; ## [1] &quot;Argentina&quot; &quot;Bolivia&quot; &quot;Brazil&quot; &quot;India&quot; &quot;Indonesia&quot; &quot;Mexico&quot; &quot;Philippines&quot; &quot;Singapore&quot; ## [9] &quot;Thailand&quot; &quot;Venezuela&quot; amount_factor(tables$gapminderDB$country) ## [1] &quot;tables$gapminderDB$country has 185 levels:&quot; ## [1] &quot;Albania&quot; &quot;Algeria&quot; &quot;Angola&quot; ## [4] &quot;Antigua and Barbuda&quot; &quot;Argentina&quot; &quot;Armenia&quot; ## [7] &quot;Aruba&quot; &quot;Australia&quot; &quot;Austria&quot; ## [10] &quot;Azerbaijan&quot; &quot;Bahamas&quot; &quot;Bahrain&quot; ## [13] &quot;Bangladesh&quot; &quot;Barbados&quot; &quot;Belarus&quot; ## [16] &quot;Belgium&quot; &quot;Belize&quot; &quot;Benin&quot; ## [19] &quot;Bhutan&quot; &quot;Bolivia&quot; &quot;Bosnia and Herzegovina&quot; ## [22] &quot;Botswana&quot; &quot;Brazil&quot; &quot;Brunei&quot; ## [25] &quot;Bulgaria&quot; &quot;Burkina Faso&quot; &quot;Burundi&quot; ## [28] &quot;Cambodia&quot; &quot;Cameroon&quot; &quot;Canada&quot; ## [31] &quot;Cape Verde&quot; &quot;Central African Republic&quot; &quot;Chad&quot; ## [34] &quot;Chile&quot; &quot;China&quot; &quot;Colombia&quot; ## [37] &quot;Comoros&quot; &quot;Congo, Dem. Rep.&quot; &quot;Congo, Rep.&quot; ## [40] &quot;Costa Rica&quot; &quot;Cote d&#39;Ivoire&quot; &quot;Croatia&quot; ## [43] &quot;Cuba&quot; &quot;Cyprus&quot; &quot;Czech Republic&quot; ## [46] &quot;Denmark&quot; &quot;Djibouti&quot; &quot;Dominican Republic&quot; ## [49] &quot;Ecuador&quot; &quot;Egypt&quot; &quot;El Salvador&quot; ## [52] &quot;Equatorial Guinea&quot; &quot;Eritrea&quot; &quot;Estonia&quot; ## [55] &quot;Ethiopia&quot; &quot;Fiji&quot; &quot;Finland&quot; ## [58] &quot;France&quot; &quot;French Polynesia&quot; &quot;Gabon&quot; ## [61] &quot;Gambia&quot; &quot;Georgia&quot; &quot;Germany&quot; ## [64] &quot;Ghana&quot; &quot;Greece&quot; &quot;Greenland&quot; ## [67] &quot;Grenada&quot; &quot;Guatemala&quot; &quot;Guinea&quot; ## [70] &quot;Guinea-Bissau&quot; &quot;Guyana&quot; &quot;Haiti&quot; ## [73] &quot;Honduras&quot; &quot;Hong Kong, China&quot; &quot;Hungary&quot; ## [76] &quot;Iceland&quot; &quot;India&quot; &quot;Indonesia&quot; ## [79] &quot;Iran&quot; &quot;Iraq&quot; &quot;Ireland&quot; ## [82] &quot;Israel&quot; &quot;Italy&quot; &quot;Jamaica&quot; ## [85] &quot;Japan&quot; &quot;Jordan&quot; &quot;Kazakhstan&quot; ## [88] &quot;Kenya&quot; &quot;Kiribati&quot; &quot;Kuwait&quot; ## [91] &quot;Kyrgyz Republic&quot; &quot;Lao&quot; &quot;Latvia&quot; ## [94] &quot;Lebanon&quot; &quot;Lesotho&quot; &quot;Liberia&quot; ## [97] &quot;Libya&quot; &quot;Lithuania&quot; &quot;Luxembourg&quot; ## [100] &quot;Macao, China&quot; &quot;Macedonia, FYR&quot; &quot;Madagascar&quot; ## [103] &quot;Malawi&quot; &quot;Malaysia&quot; &quot;Maldives&quot; ## [106] &quot;Mali&quot; &quot;Malta&quot; &quot;Mauritania&quot; ## [109] &quot;Mauritius&quot; &quot;Mexico&quot; &quot;Micronesia, Fed. Sts.&quot; ## [112] &quot;Moldova&quot; &quot;Mongolia&quot; &quot;Montenegro&quot; ## [115] &quot;Morocco&quot; &quot;Mozambique&quot; &quot;Namibia&quot; ## [118] &quot;Nepal&quot; &quot;Netherlands&quot; &quot;New Caledonia&quot; ## [121] &quot;New Zealand&quot; &quot;Nicaragua&quot; &quot;Niger&quot; ## [124] &quot;Nigeria&quot; &quot;Norway&quot; &quot;Oman&quot; ## [127] &quot;Pakistan&quot; &quot;Panama&quot; &quot;Papua New Guinea&quot; ## [130] &quot;Paraguay&quot; &quot;Peru&quot; &quot;Philippines&quot; ## [133] &quot;Poland&quot; &quot;Portugal&quot; &quot;Puerto Rico&quot; ## [136] &quot;Qatar&quot; &quot;Romania&quot; &quot;Russia&quot; ## [139] &quot;Rwanda&quot; &quot;Samoa&quot; &quot;Saudi Arabia&quot; ## [142] &quot;Senegal&quot; &quot;Serbia&quot; &quot;Seychelles&quot; ## [145] &quot;Sierra Leone&quot; &quot;Singapore&quot; &quot;Slovak Republic&quot; ## [148] &quot;Slovenia&quot; &quot;Solomon Islands&quot; &quot;South Africa&quot; ## [151] &quot;South Korea&quot; &quot;Spain&quot; &quot;Sri Lanka&quot; ## [154] &quot;St. Lucia&quot; &quot;St. Vincent and the Grenadines&quot; &quot;Sudan&quot; ## [157] &quot;Suriname&quot; &quot;Swaziland&quot; &quot;Sweden&quot; ## [160] &quot;Switzerland&quot; &quot;Syria&quot; &quot;Tajikistan&quot; ## [163] &quot;Tanzania&quot; &quot;Thailand&quot; &quot;Timor-Leste&quot; ## [166] &quot;Togo&quot; &quot;Tonga&quot; &quot;Trinidad and Tobago&quot; ## [169] &quot;Tunisia&quot; &quot;Turkey&quot; &quot;Turkmenistan&quot; ## [172] &quot;Uganda&quot; &quot;Ukraine&quot; &quot;United Arab Emirates&quot; ## [175] &quot;United Kingdom&quot; &quot;United States&quot; &quot;Uruguay&quot; ## [178] &quot;Uzbekistan&quot; &quot;Vanuatu&quot; &quot;Venezuela&quot; ## [181] &quot;Vietnam&quot; &quot;West Bank and Gaza&quot; &quot;Yemen&quot; ## [184] &quot;Zambia&quot; &quot;Zimbabwe&quot; levelF &lt;- tables$fluDB$country %&gt;% as.factor %&gt;% levels() levelD &lt;- tables$dengueDB$country %&gt;% as.factor %&gt;% levels() levelG &lt;- tables$gapminderDB$country %&gt;% as.factor %&gt;% levels() common(levelD, levelG) ## [1] &quot;Argentina&quot; &quot;Bolivia&quot; &quot;Brazil&quot; &quot;India&quot; &quot;Indonesia&quot; &quot;Mexico&quot; &quot;Philippines&quot; &quot;Singapore&quot; ## [9] &quot;Thailand&quot; &quot;Venezuela&quot; All the countries in the dengue data set are all also in the gapminder dataset. common(levelD, levelF) ## [1] &quot;Argentina&quot; &quot;Bolivia&quot; &quot;Brazil&quot; &quot;Mexico&quot; common(levelF, levelG) %&gt;% length() ## [1] &quot;Argentina&quot; &quot;Australia&quot; &quot;Austria&quot; &quot;Belgium&quot; &quot;Bolivia&quot; &quot;Brazil&quot; &quot;Bulgaria&quot; &quot;Canada&quot; ## [9] &quot;Chile&quot; &quot;France&quot; &quot;Germany&quot; &quot;Hungary&quot; &quot;Japan&quot; &quot;Mexico&quot; &quot;Netherlands&quot; &quot;Norway&quot; ## [17] &quot;Paraguay&quot; &quot;Peru&quot; &quot;Poland&quot; &quot;Romania&quot; &quot;Russia&quot; &quot;Spain&quot; &quot;Sweden&quot; &quot;Switzerland&quot; ## [25] &quot;Ukraine&quot; &quot;Uruguay&quot; ## [1] 26 but the flu data set only has in common with the dengue data set. If the tables are to be joined they need to have data about only the countries and years equal to the counties and years that the tables have in common. Or the tables need to be joined in a way that NA is introduced where necessary. gapminder_02_15 &lt;- tables$gapminderDB %&gt;% filter(between(year, 2002, 2015)) 10. Save this clean gapminder data in the workflowsdb database dbWriteTable(con, &quot;gapminder_02_15DB&quot;, gapminder_02_15, overwrite = T) 11. Perform some joins (your choice) with SQL (can be done in DBeaver or with dplyr). SELECT &quot;gapminder_02_15DB&quot;.*, &quot;fluDB&quot;.influenza_activity, &quot;dengueDB&quot;.dengue_activity FROM &quot;gapminder_02_15DB&quot; LEFT JOIN &quot;fluDB&quot; ON public.&quot;fluDB&quot;.year = public.&quot;gapminder_02_15DB&quot;.year AND public.&quot;fluDB&quot;.country = public.&quot;gapminder_02_15DB&quot;.country LEFT JOIN &quot;dengueDB&quot; ON public.&quot;dengueDB&quot;.year = public.&quot;gapminder_02_15DB&quot;.year AND public.&quot;dengueDB&quot;.country = public.&quot;gapminder_02_15DB&quot;.country Table 8.4: Displaying records 1 - 10 country year infant_mortality life_expectancy fertility population gdp continent region influenza_activity dengue_activity Argentina 2002 17.1 74.3 2.38 37889443 2.420762e+11 Americas South America 0 0.000 Australia 2002 5.0 80.3 1.76 19514385 4.421354e+11 Oceania Australia and New Zealand 0 NA Austria 2002 4.4 78.8 1.39 8114698 1.969986e+11 Europe Western Europe 0 NA Belgium 2002 4.4 78.2 1.68 10364613 2.377417e+11 Europe Western Europe 0 NA Bolivia 2002 53.7 68.7 3.98 8653343 8.751510e+09 Americas South America 0 0.101 Brazil 2002 24.3 71.4 2.26 181045592 6.705127e+11 Americas South America 174 0.073 Bulgaria 2002 16.3 72.1 1.22 7869124 1.406418e+10 Europe Eastern Europe 0 NA Canada 2002 5.3 79.6 1.51 31288572 7.594286e+11 Americas Northern America 0 NA Chile 2002 8.3 77.7 2.01 15544554 7.944855e+10 Americas South America 0 NA France 2002 4.2 79.4 1.87 60075783 1.363229e+12 Europe Western Europe 0 NA 12. Generate a joined table, and export this from the database to R. CREATE TABLE joined_gapfluden AS SELECT &quot;gapminder_02_15DB&quot;.*, &quot;fluDB&quot;.influenza_activity, &quot;dengueDB&quot;.dengue_activity FROM &quot;gapminder_02_15DB&quot; LEFT JOIN &quot;fluDB&quot; ON public.&quot;fluDB&quot;.year = public.&quot;gapminder_02_15DB&quot;.year AND public.&quot;fluDB&quot;.country = public.&quot;gapminder_02_15DB&quot;.country LEFT JOIN &quot;dengueDB&quot; ON public.&quot;dengueDB&quot;.year = public.&quot;gapminder_02_15DB&quot;.year AND public.&quot;dengueDB&quot;.country = public.&quot;gapminder_02_15DB&quot;.country joined_gapfluden &lt;- dbReadTable(conn = con, &quot;joined_gapfluden&quot;) dbDisconnect(con) 13. Show some descriptive statistics with this table, and at least 3 visualizations using ggplot2. The joined dataset contains data about R joined_gapfluden[\"country\"] %&gt;% unique() %&gt;% count() %&gt;% pull() different countries, during the time period from R joined_gapfluden[\"year\"] %&gt;% min until R joined_gapfluden[\"year\"] %&gt;% max. And also the influenza cases per country during this time. joined_gapfluden$country &lt;- joined_gapfluden$country %&gt;% as.factor() joined_gapfluden$year &lt;- joined_gapfluden$year %&gt;% as.factor() joined_gapfluden$continent &lt;- joined_gapfluden$continent %&gt;% as.factor() joined_gapfluden$region &lt;- joined_gapfluden$region %&gt;% as.factor() kableExtra::kable(head(joined_gapfluden)) country year infant_mortality life_expectancy fertility population gdp continent region influenza_activity dengue_activity Argentina 2002 17.1 74.3 2.38 37889443 242076212334 Americas South America 0 0.000 Australia 2002 5.0 80.3 1.76 19514385 442135393399 Oceania Australia and New Zealand 0 NA Austria 2002 4.4 78.8 1.39 8114698 196998621885 Europe Western Europe 0 NA Belgium 2002 4.4 78.2 1.68 10364613 237741668285 Europe Western Europe 0 NA Bolivia 2002 53.7 68.7 3.98 8653343 8751510220 Americas South America 0 0.101 Brazil 2002 24.3 71.4 2.26 181045592 670512665737 Americas South America 174 0.073 Influenza, commonly called the flu, is an infectious disease caused by The influenza virus. Symptoms can be quite mild; fever, runny nose, sore throat. Or severe pneumonia. in 2009 a strain of influenza, the H1N1 influenza strain caused a pandemic known as the swine flu. joined_gapfluden %&gt;% ggplot(aes(x= year, y = influenza_activity, group = country, fill = country)) + geom_area(alpha = 0.7, size = 0.4, colour = &quot;white&quot;) + theme_ipsum() + #or theme_ft_rc() scale_fill_viridis(discrete = T) + labs(x = &quot;influenza cases&quot;) ## Warning: Removed 2226 rows containing missing values (position_stack). ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database Global cases peaked in 2009 at 586671. Some countries had more influenza cases realtive to their population during the peak than others. relative_influenza_2009 &lt;- joined_gapfluden %&gt;% filter(continent == &quot;Europe&quot;, year == &quot;2009&quot;) %&gt;% select(country, population, influenza_activity) %&gt;% mutate(relative_influenza_cases = (influenza_activity / population)*100) regions &lt;- relative_influenza_2009$country #remove Russia because it takes up too much space in the map regions &lt;- regions[-11] map_data_eu &lt;- map_data(&quot;world&quot;, region = regions) relative_influenza_2009 &lt;- relative_influenza_2009 %&gt;% filter(country != &quot;Russia&quot;) #renaming for left join relative_influenza_2009 &lt;- rename(relative_influenza_2009, region = country) map_data_eu &lt;- left_join(relative_influenza_2009, map_data_eu, by = &quot;region&quot;) ggplot(map_data_eu, aes(x = long, y = lat)) + geom_polygon(aes(group = group, fill = relative_influenza_cases), colour = &quot;white&quot;, size = 0.1) + theme_void() + #maybe a dark theme? scale_fill_viridis(option = &quot;E&quot;) + labs(title = &quot;Influenza Activity in europe&quot;, fill = &quot;relative influenza activity&quot;) It is visible that Austria was had a relatively high influenza activity. Could this have effected life expectancy in Austria? joined_gapfluden %&gt;% filter(country == &quot;Austria&quot;) %&gt;% ggplot() + geom_line(aes(x = year, y = life_expectancy), group = 1, size = 1) + geom_line(aes(x = year, y = influenza_activity/500), group = 1, inherit.aes = F, size = 1, color = &quot;red&quot;) + scale_y_continuous( name = &quot;Life Expectancy in years&quot;, sec.axis = sec_axis(~.*500, name = &quot;Influenza cases&quot;) ) + theme_ipsum() ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database "],["influenzadata-package.html", "9 InfluenzaData package", " 9 InfluenzaData package Ive used the RMD for portfolio exercise 7 to create a package. the github can be found here "],["parametered-rmd.html", "10 Parametered RMD", " 10 Parametered RMD data &lt;- read.csv(&quot;9_data/data.csv&quot;) data &lt;- rename(data, country = ï..country) #convert year-week format to a date fomat # using this: https://stackoverflow.com/questions/45549449/transform-year-week-to-date-object #each year-week date needs to be associated with a month, this is done most accuratly if thursday is taken as day of the week. isoweek_thursday &lt;- paste0(str_sub(data$year_week, start = 0, end = 5), &quot;W&quot;, str_sub(data$year_week, start = 6, end = 7), &quot;-4&quot;) data$date &lt;- ISOweek2date(isoweek_thursday) #reordering columns so that date is next to year_week data &lt;- data[,c(1, 2, 3, 4, 5, 6, 7, 11, 8, 9, 10)] #selecting rows based on regex: https://stackoverflow.com/questions/9520840/using-regexp-to-select-rows-in-r-dataframe data %&gt;% filter(country == params$country, indicator == &quot;cases&quot;) %&gt;% subset(grepl(paste(params$year, params$month, &quot;.*&quot;, sep = &quot;-&quot;), date)) %&gt;% ggplot() + geom_line(aes(x = date, y = cumulative_count), group = 1, size = 1, color = &quot;red&quot;) + theme_ipsum() ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database data %&gt;% filter(country == params$country, indicator == &quot;deaths&quot;) %&gt;% subset(grepl(paste(params$year, params$month, &quot;.*&quot;, sep = &quot;-&quot;), date)) %&gt;% ggplot() + geom_line(aes(x = date, y = cumulative_count), group = 1, size = 1, color = &quot;red&quot;) + theme_ipsum() ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database ## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, : font family not found in Windows font database "]]
